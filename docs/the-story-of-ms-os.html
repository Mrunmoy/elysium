<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>The Story of ms-os</title>
<style>
  @page {
    size: A4;
    margin: 2.5cm 2cm;
  }

  * { box-sizing: border-box; }

  body {
    font-family: 'Georgia', 'Times New Roman', serif;
    font-size: 11.5pt;
    line-height: 1.65;
    color: #1a1a1a;
    max-width: 700px;
    margin: 0 auto;
    padding: 2cm 1.5cm;
    background: #fff;
  }

  /* ---- Title Page ---- */
  .title-page {
    text-align: center;
    page-break-after: always;
    padding-top: 6cm;
  }
  .title-page h1 {
    font-size: 36pt;
    font-weight: 700;
    color: #1a3a5c;
    letter-spacing: 2px;
    margin-bottom: 0.2em;
  }
  .title-page .subtitle {
    font-size: 14pt;
    color: #5a7a9a;
    font-style: italic;
    margin-bottom: 3cm;
  }
  .title-page .meta {
    font-size: 11pt;
    color: #666;
    line-height: 2;
  }

  /* ---- Chapter headings ---- */
  h2.chapter {
    font-size: 22pt;
    color: #1a3a5c;
    border-bottom: 3px solid #c0392b;
    padding-bottom: 8px;
    margin-top: 2.5em;
    page-break-before: always;
  }
  h2.chapter .ch-num {
    display: block;
    font-size: 11pt;
    text-transform: uppercase;
    letter-spacing: 3px;
    color: #c0392b;
    font-weight: 400;
    margin-bottom: 4px;
  }

  h3 {
    font-size: 14pt;
    color: #2c3e50;
    margin-top: 1.8em;
    margin-bottom: 0.5em;
  }

  h4 {
    font-size: 12pt;
    color: #555;
    font-style: italic;
    margin-top: 1.4em;
    margin-bottom: 0.4em;
  }

  /* ---- Body text ---- */
  p { margin: 0.8em 0; text-align: justify; }

  strong { color: #1a3a5c; }

  em { color: #555; }

  .highlight {
    background: #fef9e7;
    border-left: 4px solid #f39c12;
    padding: 10px 14px;
    margin: 1.2em 0;
    font-size: 10.5pt;
  }

  .key-decision {
    background: #eaf2f8;
    border-left: 4px solid #2980b9;
    padding: 10px 14px;
    margin: 1.2em 0;
    font-size: 10.5pt;
  }

  .lesson {
    background: #fdedec;
    border-left: 4px solid #c0392b;
    padding: 10px 14px;
    margin: 1.2em 0;
    font-size: 10.5pt;
  }

  /* ---- Diagrams ---- */
  .diagram {
    background: #f8f9fa;
    border: 1px solid #ddd;
    border-radius: 4px;
    padding: 16px 20px;
    margin: 1.5em 0;
    font-family: 'Courier New', monospace;
    font-size: 9.5pt;
    line-height: 1.4;
    white-space: pre;
    overflow-x: auto;
    color: #2c3e50;
  }
  .diagram .label {
    color: #c0392b;
    font-weight: bold;
  }
  .diagram .comment {
    color: #7f8c8d;
  }

  /* ---- Code ---- */
  code {
    font-family: 'Courier New', monospace;
    font-size: 10pt;
    background: #f0f0f0;
    padding: 1px 5px;
    border-radius: 3px;
    color: #c0392b;
  }

  pre {
    background: #2c3e50;
    color: #ecf0f1;
    padding: 14px 18px;
    border-radius: 4px;
    font-family: 'Courier New', monospace;
    font-size: 9.5pt;
    line-height: 1.5;
    overflow-x: auto;
    margin: 1.2em 0;
  }
  pre .kw { color: #e74c3c; }
  pre .str { color: #2ecc71; }
  pre .cmt { color: #7f8c8d; }
  pre .fn { color: #f39c12; }
  pre .num { color: #9b59b6; }

  /* ---- Tables ---- */
  table {
    border-collapse: collapse;
    width: 100%;
    margin: 1.2em 0;
    font-size: 10pt;
  }
  th {
    background: #1a3a5c;
    color: white;
    padding: 8px 12px;
    text-align: left;
    font-weight: 600;
  }
  td {
    padding: 6px 12px;
    border-bottom: 1px solid #ddd;
  }
  tr:nth-child(even) { background: #f8f9fa; }

  /* ---- Timeline ---- */
  .timeline {
    position: relative;
    padding-left: 30px;
    margin: 1.5em 0;
  }
  .timeline::before {
    content: '';
    position: absolute;
    left: 8px;
    top: 0;
    bottom: 0;
    width: 3px;
    background: #1a3a5c;
  }
  .timeline .event {
    position: relative;
    margin-bottom: 1.2em;
    padding-left: 10px;
  }
  .timeline .event::before {
    content: '';
    position: absolute;
    left: -26px;
    top: 6px;
    width: 12px;
    height: 12px;
    background: #c0392b;
    border-radius: 50%;
    border: 2px solid #fff;
    box-shadow: 0 0 0 2px #1a3a5c;
  }
  .timeline .event-title {
    font-weight: 700;
    color: #1a3a5c;
  }

  /* ---- Figures ---- */
  .figure {
    text-align: center;
    margin: 1.5em 0;
  }
  .figure .caption {
    font-size: 9.5pt;
    color: #666;
    font-style: italic;
    margin-top: 6px;
  }

  /* ---- Print ---- */
  @media print {
    body { padding: 0; max-width: none; }
    .no-print { display: none; }
    h2.chapter { page-break-before: always; }
    .diagram, pre, table, .highlight, .key-decision, .lesson {
      page-break-inside: avoid;
    }
  }

  /* ---- Epigraph ---- */
  .epigraph {
    font-style: italic;
    color: #666;
    text-align: right;
    margin: 2em 0;
    padding-right: 1em;
    font-size: 11pt;
  }
  .epigraph .attribution {
    font-size: 9.5pt;
    margin-top: 4px;
  }
</style>
</head>
<body>

<!-- ============================================================ -->
<!--                        TITLE PAGE                            -->
<!-- ============================================================ -->
<div class="title-page">
  <h1>ms-os</h1>
  <div class="subtitle">Building a Real-Time Operating System from Scratch</div>
  <div style="width: 60%; margin: 0 auto; border-top: 2px solid #1a3a5c; padding-top: 1.5cm;">
    <div class="meta">
      Target: ARM Cortex-M3 / M4 / A9<br>
      Language: C++17 + Assembly<br>
      Architecture: Microkernel<br>
      <br>
      July 2025 &mdash; Present
    </div>
  </div>
</div>

<!-- ============================================================ -->
<!--                    TABLE OF CONTENTS                         -->
<!-- ============================================================ -->
<h2 class="chapter" style="page-break-before: always;">
  <span class="ch-num">&nbsp;</span>
  Contents
</h2>

<div style="font-size: 9pt; color: #999; margin-bottom: 2em;">
  Companion documents:
  <a href="architecture.html">Architecture Guide</a> |
  <a href="debugging-playbook.html">Debugging Playbook</a>
</div>

<div style="font-size: 11pt; line-height: 2.2;">
  <strong>Prologue</strong> &mdash; Why Build an OS?<br>
  <div style="margin-left: 2em; line-height: 1.8; font-size: 10pt; color: #555;">
    Why Build One at All? / Why Start Simple? / The Architecture
  </div>
  <strong>Chapter 1</strong> &mdash; Laying the Foundation (Phase 0)<br>
  <div style="margin-left: 2em; line-height: 1.8; font-size: 10pt; color: #555;">
    Setting Up the Environment / Test-Driven Development / The Dual Build System /
    The Register-Level HAL / Startup / First Light
  </div>
  <strong>Chapter 2</strong> &mdash; The Kernel Comes Alive (Phase 1)<br>
  <strong>Chapter 3</strong> &mdash; Teaching the OS to Multitask (Phase 2)<br>
  <strong>Chapter 4</strong> &mdash; Guarding Memory (Phase 3)<br>
  <strong>Chapter 5</strong> &mdash; New Horizons: The PYNQ-Z2 (Phase 4)<br>
  <div style="margin-left: 2em; line-height: 1.8; font-size: 10pt; color: #555;">
    Getting the Damn Thing to Talk / The RTOS Port / The Alignment Fault /
    The MMU Fix / The UART ID Problem / The L2 Cache Nightmare /
    JTAG Reload via Cache Invalidation / Clean SD Card Boot /
    The Remaining Battles / The Debugging Lessons
  </div>
  <strong>Chapter 6</strong> &mdash; Talking Between Threads (Phase 5)<br>
  <div style="margin-left: 2em; line-height: 1.8; font-size: 10pt; color: #555;">
    The Design Space / The 64-Byte Constraint / The Blocking Question /
    Building the Tool to Build the Tool / First Message / The Memory Budget
  </div>
  <strong>Chapter 7</strong> &mdash; Drawing the Line (Phase 6)<br>
  <div style="margin-left: 2em; line-height: 1.8; font-size: 10pt; color: #555;">
    The Privilege Boundary / The Syscall Table / First Flash /
    The Silent Failure / The Logic Chain / The Philosophical Problem /
    The Fix / The MPU Wall / Testing the Boundary
  </div>
  <strong>Chapter 8</strong> &mdash; Describing the Hardware (Phase 7)<br>
  <div style="margin-left: 2em; line-height: 1.8; font-size: 10pt; color: #555;">
    The First Attempt: YAML / The Standard / Building the Parser /
    The dt Command / Three Boards, One Format
  </div>
  <strong>Chapter 9</strong> &mdash; Conserving Every Milliamp (Phase 8)<br>
  <div style="margin-left: 2em; line-height: 1.8; font-size: 10pt; color: #555;">
    The Spinning Idle Thread / The Instruction That Changes Everything /
    The Levels of Sleep / Clock Gating / Testing the Untestable
  </div>
  <strong>Chapter 10</strong> &mdash; A Window Into the Kernel (Phase 9)<br>
  <div style="margin-left: 2em; line-height: 1.8; font-size: 10pt; color: #555;">
    The First Keypress / The ps Revelation / mem and uptime /
    Character-Driven Design / No sprintf, No Problem
  </div>
  <strong>Chapter 11</strong> &mdash; The Safety Net (CI &amp; GitHub Pages)<br>
  <div style="margin-left: 2em; line-height: 1.8; font-size: 10pt; color: #555;">
    The Matrix / The Clang Surprise / The Cross-Compilation Firewall /
    The pyserial Ambush / The README Refresh / GitHub Pages
  </div>
  <strong>Epilogue</strong> &mdash; The Road Ahead<br>
  <strong>Appendix A</strong> &mdash; Hardware Targets<br>
  <strong>Appendix B</strong> &mdash; Project Timeline
</div>

<!-- ============================================================ -->
<!--                        PROLOGUE                              -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Prologue</span>
  Why Build an OS?
</h2>

<div class="epigraph">
  "What I cannot create, I do not understand."
  <div class="attribution">&mdash; Richard Feynman</div>
</div>

<p>
Every embedded engineer has, at some point, stared at a blinking LED and
thought: <em>what if I built the entire software stack beneath this?</em>
Not just the blink loop, not just the HAL, but the scheduler that decides
when the LED thread runs, the memory allocator that gives it stack space,
the fault handler that catches it when things go wrong.
</p>

<p>
That question is the seed of <strong>ms-os</strong>.
</p>

<p>
The goal was ambitious but clear: build a <strong>real-time operating system
from scratch</strong>, in modern C++17, targeting real ARM hardware. A kernel
that boots on silicon, switches contexts in microseconds, inherits priorities
through mutexes, and prints a crash dump when the world falls apart.
</p>

<h3>Why Build One at All?</h3>

<p>
There is no shortage of excellent RTOSes in the world. FreeRTOS is battle-tested
and runs on billions of devices. ThreadX powers Azure IoT. Zephyr has a
thriving open-source community. We studied all three&mdash;their source code
lives on our development machine as reference implementations&mdash;and we
could have picked any of them and started writing applications immediately.
</p>

<p>
But using an RTOS and <em>understanding</em> an RTOS are two very different
things. We wanted to know what happens in the 50 nanoseconds between one
thread stopping and another starting. We wanted to understand <em>why</em>
PendSV runs at the lowest priority, not just that it does. We wanted to feel
the difference between a bitmap scheduler and a linked-list walk, not just
read about it in a textbook. The only way to truly learn these things is to
build them yourself, debug them on real hardware, and watch them break in
ways no tutorial ever warns you about.
</p>

<h3>Why Start Simple?</h3>

<p>
We chose an <strong>STM32F207ZGT6</strong> as the first target: a Cortex-M3
running at 120 MHz with 1 MB of flash and 128 KB of SRAM. This was a
deliberate choice. The Cortex-M3 is one of the simplest ARM cores that still
has a real exception model, an NVIC, and hardware stack frame management on
interrupt entry. There is no MMU, no cache hierarchy, no multi-core
complexity. When something goes wrong, there are fewer places to look. The
chip's reference manual is one document, not five.
</p>

<p>
Starting simple meant we could focus on getting the fundamentals right:
context switching, scheduling algorithms, synchronization primitives. Once
those worked correctly on a predictable single-core machine, we could
confidently port to more complex hardware&mdash;knowing that any new bugs
came from the port, not from the core RTOS logic. Later, a Cortex-M4
(STM32F407ZGT6) and a dual Cortex-A9 (Zynq-7020 on the PYNQ-Z2 board)
would join the family, each adding architectural challenges of its own.
</p>

<h3>The Architecture</h3>

<p>
We chose a <strong>microkernel architecture</strong>&mdash;minimal kernel
with user-space services&mdash;inspired by Minix and QNX. The kernel would
handle only scheduling, synchronization, and memory protection. Everything
else&mdash;drivers, IPC, process management&mdash;would live outside the
kernel.
</p>

<p>
This is the story of how we built it, one phase at a time.
</p>

<!-- ============================================================ -->
<!--                      CHAPTER 1                               -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 1</span>
  Laying the Foundation
</h2>

<h4>Phase 0: Toolchain, HAL, and First Light</h4>

<p>
Before you can build an OS, you need to build the ground it stands on.
Phase 0 was about establishing the entire development infrastructure:
a reproducible development environment, the cross-compilation toolchain,
the build system, the testing strategy, and the Hardware Abstraction Layer.
</p>

<h3>Setting Up the Environment</h3>

<p>
The very first thing we did&mdash;before writing a single line of C++&mdash;was
make sure anyone could reproduce the build. We chose <strong>Nix</strong> as our
package manager, because it provides deterministic, reproducible environments
that work identically on any Linux machine. A single <code>flake.nix</code> at
the project root declares everything the project needs:
</p>

<pre>
<span class="cmt"># flake.nix -- the entire development environment in one file</span>
packages = [
  gcc-arm-embedded     <span class="cmt"># ARM GCC 12.3.1 cross-compiler</span>
  cmake                <span class="cmt"># Build system generator</span>
  ninja                <span class="cmt"># Fast parallel build tool</span>
  openocd              <span class="cmt"># On-chip debugger (JTAG/SWD)</span>
  gdb                  <span class="cmt"># GNU debugger</span>
  python3 + pyserial   <span class="cmt"># Serial console + test runner</span>
  python3 + pytest     <span class="cmt"># Python-level testing</span>
  git                  <span class="cmt"># Version control</span>
  stlink               <span class="cmt"># ST-Link utilities</span>
  clang-tools          <span class="cmt"># clang-format for code style</span>
];
</pre>

<p>
To enter the development environment, you type <code>nix develop</code>. Nix
downloads and caches the exact versions of every tool, isolated from the host
system. No manual installation steps, no version conflicts, no "it works on my
machine" problems. If the flake builds today, it builds identically a year from now.
</p>

<p>
Alongside the Nix shell, we created <code>build.py</code>&mdash;a Python wrapper
around CMake and Ninja that handles the common workflows:
</p>

<pre>
python3 build.py                          <span class="cmt"># Cross-compile for F207</span>
python3 build.py --target stm32f407zgt6   <span class="cmt"># Cross-compile for F407</span>
python3 build.py --target pynq-z2         <span class="cmt"># Cross-compile for PYNQ-Z2</span>
python3 build.py -t                       <span class="cmt"># Build + run host unit tests</span>
python3 build.py -f                       <span class="cmt"># Flash firmware via J-Link</span>
python3 build.py -c                       <span class="cmt"># Clean everything</span>
</pre>

<p>
The script auto-detects target mismatches (if you switch from F207 to F407, it
cleans and reconfigures automatically) and selects the right flash tool per target
(J-Link for STM32, OpenOCD for PYNQ-Z2).
</p>

<h3>The Development Paradigm: Test-Driven Development</h3>

<p>
From the very beginning, we committed to <strong>test-driven development (TDD)</strong>
for the entire RTOS. This might sound unusual for embedded systems, where the
traditional approach is to write code, flash it to hardware, and debug with
printf or a logic analyzer. But we believed that an RTOS kernel&mdash;where a
single bug in the scheduler can silently corrupt every thread&mdash;demanded a
higher standard of confidence.
</p>

<p>
The development cycle for every component follows a strict four-phase process:
</p>

<div class="diagram">
  <span class="label">Development Phases (mandatory, in order)</span>

  1. DESIGN     Write a design document: architecture, interfaces,
                data structures, algorithms, edge cases.

  2. TEST       Write unit tests first (Google Test on x86).
                Mock the hardware. Define the expected behavior
                before writing the implementation.

  3. IMPLEMENT  Write the real code. Run tests continuously.
                The implementation is done when all tests pass.

  4. DOCUMENT   Update the design docs with what was actually built.
                Record any deviations from the original design.
</div>

<p>
Why this order? Because writing tests first forces you to think about the
<em>interface</em> before the implementation. When you write a test for
<code>heapAlloc()</code> before writing the allocator, you have to decide: what
does it return on failure? What alignment guarantees does it make? What happens
if you free a null pointer? These questions get answered in the test, not
discovered later during debugging on hardware.
</p>

<p>
TDD also gives us a safety net for refactoring. When we added MPU support in
Phase 3, we had to modify thread creation to pre-compute MPU region values.
The existing 136 tests told us immediately whether we had broken anything.
Without them, we would have had to re-verify every feature manually on hardware.
</p>

<div class="highlight">
<strong>Test count:</strong> By Phase 3, the project has <strong>136 C++ unit
tests</strong> and <strong>17 Python tests</strong>, all running on the host
machine in seconds. No hardware required to verify the kernel logic.
</div>

<h3>The Dual Build System</h3>

<p>
TDD on embedded hardware requires solving a fundamental problem: the code runs
on ARM, but we want to test on x86. Our solution was a <strong>dual build
system</strong>. The same CMake project produces two completely different outputs
depending on context:
</p>

<div class="diagram">
                    CMakeLists.txt
                         |
            +------------+------------+
            |                         |
    CMAKE_CROSSCOMPILING?       Host Build (x86)
            |                         |
   ARM Firmware (.elf)          Unit Tests
   arm-none-eabi-gcc            Native GCC
   startup + hal + app          GoogleTest + mocks
   -> build/                    -> build-test/
</div>

<p>
The key technique is <strong>link-time mock substitution</strong>. The public HAL
headers (<code>hal/inc/hal/Gpio.h</code>, etc.) are shared between both builds.
On ARM, the real implementation files (<code>hal/src/stm32f4/Gpio.cpp</code>)
access hardware registers through volatile pointers. On x86, mock implementations
(<code>test/hal/MockGpio.cpp</code>) provide the same function symbols but record
every call into global vectors. The test files then assert on the recorded state:
</p>

<pre>
<span class="cmt">// GpioTest.cpp -- test runs on x86, no hardware needed</span>
TEST(GpioTest, ToggleSetsOutputDataRegister)
{
    hal::GpioConfig cfg{};
    cfg.port = hal::GpioPort::C;
    cfg.pin = 13;
    cfg.mode = hal::GpioMode::Output;
    hal::gpioInit(cfg);

    hal::gpioToggle(hal::GpioPort::C, 13);

    <span class="cmt">// Assert the mock recorded the correct register write</span>
    EXPECT_EQ(test::g_gpioWrites.back().port, hal::GpioPort::C);
    EXPECT_EQ(test::g_gpioWrites.back().pin, 13);
}
</pre>

<div class="key-decision">
<strong>Key Decision:</strong> No <code>#ifdef</code> in any <code>.cpp</code>
file. Platform selection is purely through directory structure and CMake. The
real and mock implementations live in different directories, and CMake picks
the right one at build time. This keeps the code clean and prevents the
tangled web of conditional compilation that plagues many embedded projects.
</div>

<h3>The Register-Level HAL</h3>

<p>
With the build system and testing strategy in place, we could start writing
actual hardware code. The first decision was whether to use ST's official HAL
library (stm32f2xx_hal). We deliberately chose <strong>not to</strong>.
</p>

<p>
ST's HAL is a thick abstraction layer with hundreds of source files, its own
interrupt handler conventions, and opinions about how you should structure
your application. For an RTOS that needs to own the interrupt vector table,
manage its own stack pointers, and control exactly when interrupts are enabled
or disabled, this kind of abstraction gets in the way. We wanted to understand
every instruction between our code and the silicon.
</p>

<p>
Instead, we wrote a minimal <strong>register-level HAL</strong> that reads and
writes peripheral registers directly through volatile pointers. Only three
modules were needed to bring the board to life:
</p>

<table>
<tr><th>Module</th><th>Purpose</th><th>Key Registers</th></tr>
<tr>
  <td><strong>RCC</strong></td>
  <td>Clock tree: enable peripheral clocks</td>
  <td>RCC_AHB1ENR, RCC_APB1ENR, RCC_APB2ENR</td>
</tr>
<tr>
  <td><strong>GPIO</strong></td>
  <td>Pin configuration and toggle (LED on PC13)</td>
  <td>GPIOx_MODER, GPIOx_ODR, GPIOx_BSRR</td>
</tr>
<tr>
  <td><strong>USART</strong></td>
  <td>Serial output (TX on PA9, 115200 baud)</td>
  <td>USART_BRR, USART_CR1, USART_SR, USART_DR</td>
</tr>
</table>

<p>
Each module followed the same directory pattern&mdash;design first, write tests
against mocks, then implement the real register access:
</p>

<div class="diagram">
  hal/
    inc/hal/          <span class="comment">&lt;-- Public headers (shared with tests)</span>
      Gpio.h
      Uart.h
      Rcc.h
    src/stm32f4/      <span class="comment">&lt;-- Real implementation (register access)</span>
      Gpio.cpp
      Uart.cpp
      Rcc.cpp
  test/hal/           <span class="comment">&lt;-- Mock implementation + tests</span>
      MockGpio.cpp
      MockRegisters.h
      GpioTest.cpp
</div>

<h3>Startup: From Reset to main()</h3>

<p>
With the HAL tested on x86, we needed startup code to actually run on the
microcontroller. The startup assembly (<code>Startup.s</code>) handles the
delicate moment between power-on and C++ code. On the STM32F207, the sequence is:
</p>

<div class="diagram">
  <span class="label">Reset_Handler</span>
       |
       +---> Copy .data from FLASH to SRAM
       +---> Zero .bss
       +---> __libc_init_array()     <span class="comment">// C++ static constructors</span>
       +---> SystemInit()
       |        |
       |        +---> Configure PLL: HSE 25MHz -> 120 MHz SYSCLK
       |        +---> Flash: 3 wait states, prefetch, I/D caches
       |        +---> APB1 = 30 MHz, APB2 = 60 MHz
       |
       +---> main()
</div>

<p>
The linker script (<code>Linker.ld</code>) maps the memory regions: 1 MB of flash
at 0x08000000 for code and constants, 128 KB of SRAM at 0x20000000 for data, BSS,
a 16 KB heap, and a 4 KB main stack at the top of memory.
</p>

<h3>First Light</h3>

<p>
The moment of truth came when the LED on PC13 blinked for the first time.
A simple delay loop, a GPIO toggle, and&mdash;confirmed through a webcam
pointed at the board&mdash;the LED was alive. Serial output followed shortly
after: <code>"ms-os on STM32F207"</code> at 115200 baud.
</p>

<p>
That first blink was the result of the entire toolchain working end to end:
Nix providing the compiler, CMake selecting the right sources, the linker
script placing code at the correct flash address, the startup assembly
configuring the PLL, and the register-level HAL toggling the right GPIO pin.
Every layer had been tested independently before this moment, and they all
came together on the first try.
</p>

<p>
Phase 0 was complete. We had a reproducible build environment, a tested HAL,
a disciplined development process, and a binary running on real hardware.
The foundation was solid.
</p>

<!-- ============================================================ -->
<!--                      CHAPTER 2                               -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 2</span>
  The Kernel Comes Alive
</h2>

<h4>Phase 1: Threads, Context Switching, and Crash Dumps</h4>

<p>
With the foundation in place, it was time to build the kernel's core:
the ability to run multiple threads of execution on a single CPU.
This is the heart of any RTOS&mdash;the context switch.
</p>

<h3>The Thread Control Block</h3>

<p>
Every thread in ms-os is represented by a <strong>Thread Control Block (TCB)</strong>,
a 44-byte structure that holds everything the kernel needs to manage a thread's life:
</p>

<table>
<tr><th>Field</th><th>Size</th><th>Purpose</th></tr>
<tr><td><code>stackPointer</code></td><td>4B</td><td>Current SP (offset 0 for assembly)</td></tr>
<tr><td><code>state</code></td><td>1B</td><td>Inactive / Ready / Running / Blocked</td></tr>
<tr><td><code>id</code></td><td>1B</td><td>Thread ID (0-7)</td></tr>
<tr><td><code>basePriority</code></td><td>1B</td><td>Assigned priority (immutable)</td></tr>
<tr><td><code>currentPriority</code></td><td>1B</td><td>Effective (may be boosted)</td></tr>
<tr><td><code>name</code></td><td>4B</td><td>Debug name for crash dumps</td></tr>
<tr><td><code>stackBase</code></td><td>4B</td><td>Bottom of stack</td></tr>
<tr><td><code>stackSize</code></td><td>4B</td><td>Size in bytes</td></tr>
<tr><td><code>mpuStackRbar</code></td><td>4B</td><td>Pre-computed MPU region (Phase 3)</td></tr>
<tr><td><code>mpuStackRasr</code></td><td>4B</td><td>Pre-computed MPU config (Phase 3)</td></tr>
</table>

<p>
The <code>stackPointer</code> field sits at offset 0 deliberately. This means
the context switch assembly can load it with a single <code>ldr r0, [TCB, #0]</code>
instruction&mdash;no offset calculation needed in the hottest path of the kernel.
</p>

<h3>The Context Switch</h3>

<p>
On Cortex-M, context switching uses the <strong>PendSV</strong> exception.
PendSV runs at the lowest interrupt priority, guaranteeing it fires only after
all other ISRs complete. This is the entire context switch, in 11 steps:
</p>

<div class="diagram">
  <span class="label">PendSV_Handler</span> (Cortex-M)

   1. cpsid i              <span class="comment">// Disable interrupts</span>
   2. mrs r0, psp          <span class="comment">// Get thread's stack pointer</span>
   3. stmdb r0!, {r4-r11}  <span class="comment">// Push callee-saved registers</span>
   4. str r0, [currentTCB] <span class="comment">// Save SP in outgoing TCB</span>
   5. currentTCB = nextTCB <span class="comment">// Switch the global pointer</span>
   6. Load MPU RBAR/RASR   <span class="comment">// Update memory protection</span>
   7. ldr r0, [nextTCB]    <span class="comment">// Load incoming SP</span>
   8. ldmia r0!, {r4-r11}  <span class="comment">// Pop callee-saved registers</span>
   9. msr psp, r0          <span class="comment">// Set new stack pointer</span>
  10. cpsie i              <span class="comment">// Re-enable interrupts</span>
  11. bx 0xFFFFFFFD        <span class="comment">// Return to thread mode</span>
</div>

<p>
The magic number <code>0xFFFFFFFD</code> is the <strong>EXC_RETURN</strong>
value that tells the Cortex-M hardware: "return to Thread mode using the
Process Stack Pointer." The hardware automatically restores r0-r3, r12, LR,
PC, and xPSR from the stack.
</p>

<div class="highlight">
<strong>Performance:</strong> The entire context switch takes approximately
<strong>50 nanoseconds</strong> at 120 MHz, including the MPU region update
added in Phase 3. That's about 6 clock cycles for the software part.
</div>

<h3>The Initial Stack Frame</h3>

<p>
When a thread is created, we build a fake stack frame that looks exactly like
the thread was interrupted mid-execution. When the context switch "restores"
this frame, the CPU seamlessly begins executing the thread function:
</p>

<div class="diagram">
  High address (top of stack):
    +----------+
    |   xPSR   |  Thumb bit set (0x01000000)
    |    PC    |  --> thread entry function
    |    LR    |  --> kernelThreadExit()
    |   r12    |  0
    |  r3..r0  |  r0 = thread argument
    +----------+  <span class="comment">---- hardware restores above ----</span>
    | r11..r4  |  all zero (software-saved)
    +----------+
         ^
    stackPointer stored in TCB
</div>

<h3>When Things Go Wrong: Crash Dumps</h3>

<p>
An RTOS that silently hangs on a fault is useless. Phase 1 introduced a
<strong>three-layer crash dump system</strong> that prints a detailed
diagnostic over the serial port when a HardFault, MemManage, BusFault,
or UsageFault occurs:
</p>

<div class="diagram">
  <span class="label">Crash Dump Architecture</span>

  +-------------------+
  | FaultHandlers.s   |  Layer 1: Assembly
  | (arch-specific)   |  Captures registers, calls C++
  +-------------------+
           |
           v
  +-------------------+
  | CrashDumpArch.cpp |  Layer 2: Architecture decode
  | (arch-specific)   |  Decodes fault registers (CFSR, etc.)
  +-------------------+
           |
           v
  +-------------------+
  | CrashDump.cpp     |  Layer 3: Portable formatting
  | (shared)          |  Prints register dump, stack trace
  +-------------------+
           |
           v
  +-------------------+
  | CrashDumpBoard.cpp|  Board-specific UART output
  | (board-specific)  |  Polled TX, no interrupts, no RTOS
  +-------------------+
</div>

<p>
The crash dump output is designed to be <em>self-contained</em>: it uses polled
UART with no interrupts, no dynamic allocation, and no RTOS services. It can
print from any fault context, even if the kernel itself is corrupted.
</p>

<!-- ============================================================ -->
<!--                      CHAPTER 3                               -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 3</span>
  Teaching the OS to Multitask
</h2>

<h4>Phase 2: The Priority Scheduler, Mutexes, and Semaphores</h4>

<p>
A context switch is just the mechanism. Phase 2 added the <em>policy</em>:
a preemptive priority-based scheduler that decides <em>which</em> thread
runs and <em>when</em> it runs.
</p>

<h3>The Bitmap Scheduler</h3>

<p>
The scheduler supports <strong>32 priority levels</strong> (0 = highest,
31 = lowest), with a per-priority FIFO queue. The key insight is a single
32-bit bitmap:
</p>

<div class="diagram">
  m_readyBitmap:

  Bit:  31 30 29 28  ...  3  2  1  0
        [0][0][1][0] ... [1][0][0][1]
                ^          ^        ^
                |          |        |
           Priority 29  Prio 3   Prio 0
           (1 thread)  (1 thread) (highest ready)

  Highest ready = __builtin_ctz(bitmap) = 0
  ARM instruction: RBIT + CLZ  -->  <span class="label">O(1)</span>
</div>

<p>
Each set bit indicates that at least one thread is ready at that priority level.
Finding the highest-priority ready thread is a single <code>__builtin_ctz</code>
(Count Trailing Zeros), which maps directly to the ARM <code>RBIT + CLZ</code>
instruction pair. <strong>O(1) scheduling, regardless of thread count.</strong>
</p>

<div class="key-decision">
<strong>Key Decision:</strong> 32 priorities with bitmap indexing. This matches
the Cortex-M NVIC convention (lower number = higher priority) and provides
constant-time scheduling. FreeRTOS uses a similar approach.
</div>

<h3>Time Slicing</h3>

<p>
Within the same priority level, threads share the CPU using <strong>round-robin
time slicing</strong>. Each thread has a configurable time slice (in ticks).
When a thread's slice expires, the scheduler moves it to the tail of its
priority queue and runs the next thread at the same level:
</p>

<div class="diagram">
  Priority 8 queue:    [Thread A] --> [Thread B] --> [Thread C]
                           ^                            |
                           |____________________________|
                                (round-robin rotation)

  SysTick fires every 1 ms.
  Thread A's slice expires after 10 ticks.
  A moves to tail, B runs next.
</div>

<h3>The Priority Inversion Problem</h3>

<p>
One of the most subtle bugs in RTOS design is <strong>priority inversion</strong>.
Imagine three threads:
</p>

<div class="diagram">
  Thread H (high priority)   -- needs Mutex M
  Thread M (medium priority) -- CPU-bound, doesn't need M
  Thread L (low priority)    -- holds Mutex M

  Without priority inheritance:
    1. L runs, acquires Mutex M
    2. H wakes up, preempts L, tries to lock M --> blocked
    3. M wakes up, preempts L (medium > low)
    4. M runs indefinitely. H starves.
       L can never finish to release M!

  <span class="label">Result: High-priority thread blocked by medium-priority thread.</span>
</div>

<p>
The solution is <strong>priority inheritance</strong>: when Thread H blocks on
a mutex held by Thread L, the kernel <em>temporarily boosts</em> L's priority
to match H's. This prevents Thread M from preempting L, allowing L to finish
quickly and release the mutex.
</p>

<div class="key-decision">
<strong>Key Decision:</strong> Priority inheritance is mandatory on all mutexes.
There is no option to create a non-inheriting mutex. This eliminates an entire
class of bugs at the cost of slightly more complex mutex code.
</div>

<h3>Synchronization Primitives</h3>

<p>
Phase 2 delivered two synchronization primitives:
</p>

<table>
<tr><th>Primitive</th><th>Properties</th><th>Use Case</th></tr>
<tr>
  <td><strong>Mutex</strong></td>
  <td>Recursive, priority-inheriting, ownership-tracked</td>
  <td>Protecting shared data structures</td>
</tr>
<tr>
  <td><strong>Semaphore</strong></td>
  <td>Counting (0..maxCount), no ownership, priority-sorted waiters</td>
  <td>Producer-consumer, resource counting</td>
</tr>
</table>

<p>
Both use a shared <strong>priority-sorted wait queue</strong>: when multiple
threads are waiting, the highest-priority one is woken first.
</p>

<h3>Sleep and the Tick</h3>

<p>
The <strong>SysTick</strong> timer fires every 1 millisecond. Each tick:
</p>

<ol>
  <li>Increments the global tick counter</li>
  <li>Checks sleeping threads (wake any whose timeout expired)</li>
  <li>Calls <code>scheduler.tick()</code> to check preemption and time slices</li>
  <li>If a context switch is needed, pends PendSV</li>
</ol>

<p>
<code>sleep(1000)</code> blocks a thread for approximately one second.
The wakeup is checked every tick, giving 1 ms resolution.
</p>

<!-- ============================================================ -->
<!--                      CHAPTER 4                               -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 4</span>
  Guarding Memory
</h2>

<h4>Phase 3: Block Pool, Heap, and the MPU</h4>

<p>
With scheduling working, the next challenge was memory management.
An RTOS needs two things: fast, deterministic allocation for kernel objects,
and flexible allocation for user applications. Phase 3 delivered both,
plus hardware memory protection.
</p>

<h3>The Block Pool: O(1) Fixed-Size Allocation</h3>

<p>
For kernel-internal objects (TCBs, message buffers, timer blocks), we need
allocation that is <strong>deterministic</strong> and <strong>ISR-safe</strong>.
The Block Pool provides this through an embedded free-list:
</p>

<div class="diagram">
  <span class="label">Block Pool (embedded free-list)</span>

  freeHead
     |
     v
  +------+    +------+    +------+    +------+
  | next-+--->| next-+--->| next-+--->| NULL |
  |      |    |      |    |      |    |      |
  | 32B  |    | 32B  |    | 32B  |    | 32B  |
  +------+    +------+    +------+    +------+

  allocate(): pop head      <span class="comment">--> O(1)</span>
  free(ptr):  push to head  <span class="comment">--> O(1)</span>

  Each free block stores the "next" pointer in its own memory.
  No separate metadata table needed.
</div>

<p>
The minimum block size is <code>sizeof(void*)</code> (4 bytes on ARM), since
each free block must hold the next pointer. The <code>free()</code> function
validates bounds and alignment before accepting a pointer back.
</p>

<h3>The Heap: First-Fit with Coalescing</h3>

<p>
For user applications&mdash;<code>std::vector</code>, <code>std::unique_ptr</code>,
<code>new</code>/<code>delete</code>&mdash;we built a variable-size heap allocator
using the classic <strong>first-fit free-list with immediate coalescing</strong>:
</p>

<div class="diagram">
  <span class="label">Heap Free List (address-sorted)</span>

  sentinel                                          sentinel
  (head)                                            (end)
     |                                                 |
     v                                                 v
  +------+    +--------+    +--------+    +---------+  +------+
  | sz=0 |    | sz=64  |    | sz=256 |    | sz=1024 |  | sz=0 |
  | next-+--->| next  -+--->| next  -+--->| next   -+->| NULL |
  +------+    | (free) |    | ALLOC  |    | (free)  |  +------+
              +--------+    +--------+    +---------+
              0x20001000    0x20001040    0x20001140

  <span class="comment">Allocation: walk list, find first block >= size</span>
  <span class="comment">Free: insert at correct address, merge with neighbors</span>
</div>

<p>
The free list is kept <strong>sorted by address</strong>. This is the crucial
insight: when freeing a block, we can check if the previous and next blocks
in the list are physically adjacent. If so, we <strong>coalesce immediately</strong>,
merging them into a single larger block. This prevents fragmentation from
accumulating over time.
</p>

<div class="highlight">
<strong>Block header:</strong> 8 bytes. Bit 0 of the size field doubles as the
allocated/free flag. A sentinel block at the heap end (size=0, allocated)
eliminates boundary checks during coalescing.
</div>

<h3>C++ Operator Overloads</h3>

<p>
To make the heap seamless for C++ applications, we override the global
<code>operator new</code> and <code>operator delete</code> to route through
our heap. A <code>_sbrk</code> stub prevents newlib's malloc from competing.
This means standard C++ works naturally:
</p>

<pre>
<span class="kw">auto</span> vec = <span class="kw">std::make_unique</span>&lt;std::vector&lt;<span class="kw">int</span>&gt;&gt;();
vec-&gt;push_back(<span class="num">42</span>);  <span class="cmt">// Allocates from kernel heap</span>
<span class="cmt">// vec automatically freed when unique_ptr goes out of scope</span>
</pre>

<h3>The MPU: Hardware-Enforced Boundaries</h3>

<p>
The ARMv7-M Memory Protection Unit provides hardware enforcement of memory
access rules. We configure 6 of the 8 available regions:
</p>

<div class="diagram">
  <span class="label">MPU Region Map</span>

  Region 0: FLASH (0x08000000)      [Priv+Unpriv RO] [Execute OK]
  Region 1: Kernel SRAM (0x20000000) [Priv RW only]   [No Execute]
  Region 2: Peripherals (0x40000000) [Priv RW only]   [No Execute]
  Region 3: System (0xE0000000)      [Priv RW only]   [No Execute]
  Region 4: Thread Stack (dynamic)   [Full Access]    [No Execute]
  Region 5: Heap (from linker)       [Full Access]    [No Execute]

  Region 4 is updated on every context switch.
  RBAR/RASR pre-computed in TCB for speed.
</div>

<div class="key-decision">
<strong>Key Decision:</strong> <code>PRIVDEFENA = 1</code> (privileged default
map enabled). All threads currently run in privileged mode with default
memory access. The MPU primarily protects against wild pointer writes
and code execution from data regions. Full unprivileged thread isolation
is deferred to a future phase.
</div>

<!-- ============================================================ -->
<!--                      CHAPTER 5                               -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 5</span>
  New Horizons: The PYNQ-Z2
</h2>

<h4>Phase 4: Porting to Cortex-A9</h4>

<div class="epigraph">
  "If debugging is the process of removing bugs, then programming
  must be the process of putting them in."
  <div class="attribution">&mdash; Edsger W. Dijkstra</div>
</div>

<p>
With the RTOS running on two Cortex-M targets (F207 and F407), we turned
to something fundamentally different: the <strong>PYNQ-Z2</strong> board,
built around the <strong>Xilinx Zynq-7020 SoC</strong>&mdash;a dual
Cortex-A9 MPCore at 650 MHz with 512 MB of DDR3.
</p>

<p>
This wasn't just a new chip. It was a <strong>new architecture</strong>.
Everything we knew about Cortex-M had to be re-examined. The exception model,
the context switch mechanism, the memory system, even the way you set up a
damn stack pointer&mdash;all different. And the debugging story that followed
would become the most intense, most frustrating, and ultimately most
satisfying chapter of this entire project.
</p>

<table>
<tr><th>Feature</th><th>Cortex-M</th><th>Cortex-A9</th></tr>
<tr><td>Instruction set</td><td>Thumb-2</td><td>ARM (32-bit)</td></tr>
<tr><td>Exception model</td><td>NVIC (nested, automatic stacking)</td><td>Banked modes (IRQ, SVC, ABT, etc.)</td></tr>
<tr><td>Context switch</td><td>PendSV (dedicated exception)</td><td>IRQ epilogue + SGI</td></tr>
<tr><td>Tick timer</td><td>SysTick (built-in)</td><td>SCU Private Timer</td></tr>
<tr><td>Memory protection</td><td>MPU (8 regions)</td><td>MMU (page tables)</td></tr>
<tr><td>Stack pointer</td><td>MSP/PSP (hardware banked)</td><td>Per-mode banked SP</td></tr>
<tr><td>First thread launch</td><td>SVC + EXC_RETURN</td><td>SVC + RFE</td></tr>
<tr><td>CPU count</td><td>Single core</td><td>Dual core (SMP capable)</td></tr>
</table>

<h3>Phase 4A: Getting the Damn Thing to Talk</h3>

<p>
The first order of business: prove that we can run <em>any</em> bare-metal
code on the Zynq. We wrote new startup assembly in ARM mode (not Thumb),
a DDR-based linker script, and a Zynq PS UART0 driver using the Cadence
UART IP. Simple stuff, right? The "hello world" of embedded. Spoiler: it
was anything but simple.
</p>

<h4>The FTDI Setup</h4>

<p>
The PYNQ-Z2 has an <strong>FTDI FT2232</strong> dual-channel USB chip.
Channel 0 is JTAG. Channel 1 is the serial console. On our Linux box, this
shows up as <code>/dev/ttyUSB1</code> for JTAG and <code>/dev/ttyUSB2</code>
for serial (because there's another FTDI device already claiming ttyUSB0).
</p>

<p>
OpenOCD talks to the JTAG channel. Our first config file:
</p>

<pre>
<span class="cmt"># pynq_load.cfg</span>
adapter driver ftdi
ftdi vid_pid 0x0403 0x6010
ftdi channel 0
ftdi layout_init 0x0008 0x000b
adapter speed 10000

set CHIPNAME zynq
source [find target/zynq_7000.cfg]
</pre>

<p>
The <code>ftdi layout_init</code> values (0x0008, 0x000b) configure the FTDI
GPIOs for JTAG signaling. Get these wrong and OpenOCD silently fails to
detect the TAP. We got these from the PYNQ-Z2 schematic.
</p>

<h4>Boot Strategy: Let u-boot Do the Hard Work</h4>

<p>
Zynq PS initialization is brutal. The Processing System (PS) has its own
PLL tree, DDR controller, MIO pin muxing, SLCR (System Level Control
Registers)&mdash;hundreds of registers that must be configured in the right
order before you can even access DDR memory. Xilinx normally generates a
<code>ps7_init.c</code> from the Vivado hardware design, and the FSBL
(First Stage Boot Loader) calls it during boot.
</p>

<p>
We took a shortcut: let the normal boot process (BootROM -> FSBL -> u-boot)
initialize the hardware, then halt via JTAG and load our binary into DDR.
This means u-boot has already configured PLLs, DDR, MIO pins&mdash;everything.
We just set our clock globals to match and go:
</p>

<pre>
<span class="cmt">// SystemInit.cpp for PYNQ-Z2 -- u-boot already configured clocks</span>
SystemCoreClock = <span class="num">650000000</span>;   <span class="cmt">// CPU at 650 MHz</span>
g_apb1Clock     = <span class="num">100000000</span>;   <span class="cmt">// UART ref clock at 100 MHz</span>
g_apb2Clock     = <span class="num">100000000</span>;
</pre>

<div class="key-decision">
<strong>Key Decision:</strong> Use u-boot for PS initialization during
development. This lets us focus on the RTOS itself rather than Zynq PS
bringup. A proper standalone boot (using <code>ps7_init</code> or our own
initialization) is deferred to when we write our custom bootloader.
</div>

<h4>The UART: Cadence IP, Not STM32</h4>

<p>
The Zynq PS UART is a <strong>Cadence UART</strong> IP core. Completely
different register layout from the STM32 USART. The baud rate formula alone
is different:
</p>

<div class="diagram">
  <span class="label">Baud Rate Calculation</span>

  STM32:  baud = f_pclk / USARTDIV
  Zynq:   baud = uart_ref_clk / (CD * (BDIV + 1))

  For 115200 baud with 100 MHz ref clock:
    BDIV = 4   (divider + 1 = 5)
    CD = 100,000,000 / (115,200 * 5) = 173.6  -->  CD = 173

  Actual baud = 100,000,000 / (173 * 5) = 115,607
  Error: 0.35%  (well within tolerance)
</pre>
</div>

<p>
PS UART0 lives at <code>0xE0000000</code>. UART1 at <code>0xE0001000</code>.
On the PYNQ-Z2, UART0 is connected to the FTDI chip for serial console
output. This distinction would come back to bite us later.
</p>

<h4>The First UART Bug: STARTBRK</h4>

<p>
Our first attempt at UART output produced... nothing. Absolute silence.
The UART was "enabled" according to the status register, but no characters
came out. We spent hours checking baud rate calculations, MIO pin
assignments, clock enables.
</p>

<p>
The problem? Our UART Control Register bit definitions were <strong>wrong</strong>.
We had defined bit 8 as "reset TX path" based on a quick read of the
register map. But bit 8 of the Cadence UART CR is actually
<code>STARTBRK</code>&mdash;it forces the TXD line permanently LOW,
asserting a break condition. We were telling the UART to hold the
line low forever while trying to transmit data on it.
</p>

<div class="lesson">
<strong>Lesson learned the hard way:</strong> Always cross-reference
register bit definitions against the actual TRM, not against quick
summaries or "similar" peripherals. One wrong bit in a control register
can produce symptoms that look like a completely different problem.
The CR register writes <code>STPBRK | TXEN | RXEN = 0x114</code>.
That took an embarrassingly long time to figure out.
</div>

<h4>Cross-Compilation Working</h4>

<p>
With the UART driver fixed and the build system extended for
<code>--target pynq-z2</code>, we could cross-compile both the hello app
and the full threads app. The binary sizes:
</p>

<table>
<tr><th>App</th><th>.text</th><th>Total</th></tr>
<tr><td>hello (bare-metal)</td><td>~2 KB</td><td>~2 KB</td></tr>
<tr><td>threads (full RTOS)</td><td>10,504 B</td><td>~42 KB</td></tr>
</table>

<p>
Both compiled cleanly. We loaded hello via JTAG and... got serial output!
Proof that the toolchain, linker script, startup assembly, and UART driver
all worked. Time to try the RTOS.
</p>

<h3>Phase 4B: The RTOS Port</h3>

<p>
The cross-compilation changes for Cortex-A9 RTOS were substantial. We had
to rethink every architecture-dependent component.
</p>

<h4>The Architecture Abstraction</h4>

<p>
To support both Cortex-M and Cortex-A9 from the same kernel source, we
introduced <code>kernel/inc/kernel/Arch.h</code>&mdash;a common interface
with per-architecture implementations selected at build time:
</p>

<div class="diagram">
  <span class="label">Arch.h (common interface)</span>

  arch::triggerContextSwitch()    <span class="comment">// M: PendSV    A9: SGI #0</span>
  arch::configureSysTick(ticks)   <span class="comment">// M: SysTick   A9: Private Timer</span>
  arch::enterCritical()           <span class="comment">// M: cpsid i   A9: cpsid i</span>
  arch::exitCritical()            <span class="comment">// M: cpsie i   A9: cpsie i</span>
  arch::startFirstThread()        <span class="comment">// M: SVC       A9: SVC</span>
  arch::initialStatusRegister()   <span class="comment">// M: 0x01000000 (Thumb)</span>
                                  <span class="comment">// A9: 0x1F (SYS mode, ARM)</span>
</div>

<h4>The Context Switch: No PendSV, No Problem (Sort Of)</h4>

<p>
On Cortex-M, context switching is beautiful. PendSV fires at the lowest
interrupt priority, guaranteeing it runs after all ISRs complete. The hardware
automatically saves half the register file on entry. You pend it from anywhere,
and it just... happens.
</p>

<p>
Cortex-A9 has none of that. There is no PendSV. There is no automatic register
stacking. There is no EXC_RETURN magic value. Instead, you have <strong>banked
processor modes</strong> (IRQ, SVC, SYS, ABT, UND, FIQ), each with their own
stack pointer and link register. The context switch happens <em>inside the
IRQ handler epilogue</em>:
</p>

<div class="diagram">
  <span class="label">Cortex-A9 Context Switch (in IRQ handler)</span>

  IRQ Entry:
    sub lr, lr, #4          <span class="comment">// Adjust return address (ARM pipeline)</span>
    srsdb sp!, #0x1F        <span class="comment">// Save {LR_irq, SPSR_irq} to SYS stack</span>
    cps #0x1F               <span class="comment">// Switch to SYS mode</span>
    push {r0-r3, r12, lr}   <span class="comment">// Save caller-saved regs on SYS stack</span>

  &lt;--- Acknowledge GIC, dispatch handler (timer / SGI) ---&gt;

  IRQ Epilogue (context switch point):
    if g_currentTcb != g_nextTcb:
      push {r4-r11}         <span class="comment">// Save callee-saved on outgoing stack</span>
      Save SP to outgoing TCB
      Switch TCB pointers
      Load SP from incoming TCB
      pop {r4-r11}          <span class="comment">// Restore callee-saved from incoming stack</span>

    pop {r0-r3, r12, lr}    <span class="comment">// Restore caller-saved</span>
    rfeia sp!                <span class="comment">// Atomically restore PC + CPSR</span>
</div>

<p>
The key instructions are <code>SRS</code> (Store Return State) and
<code>RFE</code> (Return From Exception). <code>SRS</code> saves the
interrupted thread's PC and CPSR to the <em>SYS mode stack</em>, even
though we're in IRQ mode when it executes. <code>RFE</code> atomically
restores both PC and CPSR from the stack, returning to the correct mode
and address. These are the A-profile equivalents of M-profile's automatic
stacking and EXC_RETURN.
</p>

<p>
For the trigger mechanism, we use <strong>SGI #0</strong> (Software Generated
Interrupt). When the scheduler decides a context switch is needed, it writes
to the GIC SGIR register to generate interrupt ID 0. The IRQ handler checks
the interrupt ID: if it's 29 (private timer), it handles the tick; if it's
0 (SGI), it's a context switch request. Either way, the epilogue checks
whether <code>g_currentTcb != g_nextTcb</code> and switches if needed.
</p>

<h4>The GIC and Private Timer</h4>

<p>
Cortex-M has the NVIC (simple, memory-mapped, one register per interrupt).
Cortex-A9 has the <strong>GIC</strong> (Generic Interrupt Controller)&mdash;a
two-part beast with a Distributor and a CPU Interface:
</p>

<div class="diagram">
  <span class="label">GIC Configuration</span>

  Distributor (0xF8F01000):
    DIST_CTRL = 0x3           <span class="comment">// Enable secure + non-secure</span>
    EN_SET0   = 0x2000FFFF    <span class="comment">// SGIs 0-15 + IRQ 29 (timer)</span>
    PRIORITY  = 0xA0 (timer)  <span class="comment">// Timer at priority 0xA0</span>
                0xF0 (SGI #0) <span class="comment">// SGI at lower priority 0xF0</span>

  CPU Interface (0xF8F00100):
    CPU_CTRL  = 0x3           <span class="comment">// Enable interface</span>
    PRI_MASK  = 0xF8          <span class="comment">// Allow priorities 0x00-0xF0</span>
</div>

<p>
The <strong>SCU Private Timer</strong> at <code>0xF8F00600</code> replaces
SysTick. It runs at PERIPHCLK = CPU_CLK/2 = 325 MHz. For a 1 ms tick:
load value = 325,000,000 / 1000 - 1 = 324,999 (<code>0x4F587</code>).
Auto-reload, interrupt enabled.
</p>

<h4>Crash Dumps on A-Profile</h4>

<p>
Cortex-M has dedicated fault status registers (CFSR, HFSR, MMFAR, BFAR)
that tell you exactly what went wrong. Cortex-A9 has different registers:
</p>

<table>
<tr><th>Cortex-M</th><th>Cortex-A9</th><th>Purpose</th></tr>
<tr><td>SCB->CFSR</td><td>CP15 DFSR / IFSR</td><td>Fault status (type + domain)</td></tr>
<tr><td>SCB->MMFAR</td><td>CP15 DFAR / IFAR</td><td>Faulting address</td></tr>
<tr><td>HardFault</td><td>Data Abort</td><td>Bad memory access</td></tr>
<tr><td>MemManage</td><td>Prefetch Abort</td><td>Instruction fetch fault</td></tr>
<tr><td>UsageFault</td><td>Undefined Instruction</td><td>Bad opcode</td></tr>
</table>

<p>
Our fault handlers pass a type code in <code>r1</code> (1=DataAbort,
2=PrefetchAbort, 3=Undefined) to the shared crash dump code. One fun
difference: ARM does <em>not</em> trap integer divide-by-zero (it returns 0
silently). For testing the crash dump, we use <code>UDF #0</code> (Undefined
Instruction) instead.
</p>

<h3>The Bringup: Where Everything Falls Apart (and Comes Back Together)</h3>

<p>
The cross-compilation was done. Both hello and threads built cleanly for
Cortex-A9. Time for hardware. What followed was one of the most intense
debugging sessions of the entire project&mdash;a roller coaster of
frustration, discovery, and hard-won victories.
</p>

<h4>First Boot Attempt: The Alignment Fault</h4>

<p>
We loaded the threads binary via JTAG, resumed at 0x00100000, and... the
CPU immediately faulted. Halted at the Data Abort handler. The registers
told the story:
</p>

<pre>
DFSR = 0x00000801
DFAR = 0x0010686B
PC   = somewhere in SystemInit()
</pre>

<p>
<code>DFSR = 0x801</code>. Bit 0 set = alignment fault. Bit 11 set = write
access. The faulting address <code>0x10686B</code> is clearly not
word-aligned&mdash;it ends in 0xB, not 0x0/0x4/0x8/0xC.
</p>

<p>
What the hell? We never had alignment problems on Cortex-M. Why would the
same kind of C++ code suddenly fault on unaligned access?
</p>

<p>
The answer hit us like a truck:
</p>

<div class="highlight">
<strong>On Cortex-A9 with MMU disabled, all memory is treated as
Strongly Ordered.</strong> Strongly Ordered memory requires <em>natural
alignment</em> for every access. A 32-bit store must go to a 4-byte-aligned
address. An 8-bit store is fine anywhere, but <code>str r4, [sp, #43]</code>
will fault because <code>sp + 43</code> is not 4-byte aligned.
</div>

<p>
GCC doesn't know or care about this. It freely emits unaligned stack accesses
because on Normal memory (which is what you get with the MMU enabled),
ARMv7-A handles unaligned access transparently in hardware. But with the
MMU disabled&mdash;which is the state we boot into&mdash;there is no
"Normal" memory type. Everything is Strongly Ordered. And Strongly Ordered
means: align your damn accesses or eat a Data Abort.
</p>

<p>
On Cortex-M, the MMU doesn't exist, but the default memory attributes treat
SRAM as Normal memory, so unaligned access just works. We'd never needed
to think about this. The M-profile architecture was quietly saving us from
ourselves. The A-profile was not so forgiving.
</p>

<h4>The Fix: Build an MMU Before Touching C++</h4>

<p>
The solution was clear but not trivial: we had to <strong>enable the MMU
with DDR mapped as Normal memory</strong> in the startup assembly, <em>before
any C code executes</em>. No calling SystemInit first. No calling <code>
__libc_init_array</code>. The MMU must be up and running before the first
<code>bl</code> to a C function, because even a function prologue might
push registers to an unaligned stack offset.
</p>

<p>
We implemented a flat 1:1 L1 translation table&mdash;4096 entries of 1 MB
sections covering the full 4 GB address space:
</p>

<div class="diagram">
  <span class="label">MMU L1 Translation Table (16 KB, 4096 x 4-byte entries)</span>

  Entry  0-511:   DDR (0x00000000 - 0x1FFFFFFF)
                  Normal, Inner/Outer Write-Back Write-Allocate, Shareable
                  Descriptor: 0x00011C0E
                    TEX=001, C=1, B=1, S=1, AP=11, Section (bits[1:0]=10)

  Entry 512-4095: Everything else (peripherals, PL, system registers)
                  Device, Shareable
                  Descriptor: 0x00000C06
                    TEX=000, C=0, B=1, AP=11, Section (bits[1:0]=10)
</div>

<p>
We validated the section descriptor bit fields against the Xilinx BSP
<code>translation_table.S</code> reference. The values match. TEX[2:0]=001,
C=1, B=1 gives Inner/Outer Write-Back Write-Allocate&mdash;the normal
cache policy for DDR memory.
</p>

<p>
The <code>_setup_mmu</code> routine in Startup.s builds this table at
runtime, sets TTBR0 (Translation Table Base Register 0), configures
DACR (Domain Access Control) to Manager mode (no permission checking),
and enables the MMU + I-cache + D-cache + branch prediction in SCTLR:
</p>

<pre>
<span class="cmt">// The critical sequence in Startup.s</span>
_setup_mmu:
    push    {r4, lr}

    <span class="cmt">// Fill 4096 entries: 512 Normal + 3584 Device</span>
    ldr     r0, =_mmu_table
    mov     r1, #0                  <span class="cmt">// Section base = 0x00000000</span>
    ldr     r2, =SECT_NORMAL        <span class="cmt">// 0x00011C0E</span>
    mov     r3, #512
1:  orr     r4, r2, r1
    str     r4, [r0], #4
    add     r1, r1, #0x00100000     <span class="cmt">// Next 1MB</span>
    subs    r3, r3, #1
    bne     1b

    ldr     r2, =SECT_DEVICE        <span class="cmt">// 0x00000C06</span>
    ldr     r3, =(4096 - 512)
2:  orr     r4, r2, r1
    str     r4, [r0], #4
    add     r1, r1, #0x00100000
    subs    r3, r3, #1
    bne     2b

    <span class="cmt">// Set TTBR0</span>
    ldr     r0, =_mmu_table
    mcr     p15, 0, r0, c2, c0, 0

    <span class="cmt">// DACR = Manager (full access, no permission check)</span>
    mvn     r0, #0                  <span class="cmt">// 0xFFFFFFFF</span>
    mcr     p15, 0, r0, c3, c0, 0

    <span class="cmt">// Enable MMU + caches + branch prediction in SCTLR</span>
    mrc     p15, 0, r0, c1, c0, 0
    orr     r0, r0, #(1 &lt;&lt; 0)      <span class="cmt">// MMU</span>
    orr     r0, r0, #(1 &lt;&lt; 2)      <span class="cmt">// D-cache</span>
    orr     r0, r0, #(1 &lt;&lt; 11)     <span class="cmt">// Branch prediction</span>
    orr     r0, r0, #(1 &lt;&lt; 12)     <span class="cmt">// I-cache</span>
    mcr     p15, 0, r0, c1, c0, 0
    dsb
    isb

    pop     {r4, pc}
</pre>

<p>
The linker script needed a new section for the 16 KB translation table,
aligned to 16 KB (TTBR0 requires this alignment):
</p>

<pre>
.mmu_table (NOLOAD) :
{
    . = ALIGN(16K);
    _mmu_table = .;
    . += 16K;
} > DDR
</pre>

<p>
The boot sequence now became:
</p>

<div class="diagram">
  <span class="label">Updated PYNQ-Z2 Boot Sequence</span>

  _boot:
    cpsid if                   <span class="comment">// Disable interrupts</span>
    Check MPIDR, park CPU1     <span class="comment">// Only CPU0 proceeds</span>
    Set VBAR                   <span class="comment">// Install our vector table</span>
    Disable MMU + caches       <span class="comment">// Clean slate from FSBL/u-boot</span>
    Invalidate TLBs            <span class="comment">// Stale translations</span>
    Invalidate I-cache         <span class="comment">// Stale instructions</span>
    Invalidate branch predictor
    Invalidate L1 D-cache      <span class="comment">// 4 ways x 256 sets</span>
    Disable + invalidate L2    <span class="comment">// PL310 (0xF8F02100)</span>
    <span class="label">bl _setup_mmu</span>              <span class="comment">// MMU ON before any C code!</span>
    Set per-mode stacks        <span class="comment">// IRQ, ABT, UND, FIQ, SVC, SYS</span>
    Zero .bss
    __libc_init_array          <span class="comment">// C++ static constructors</span>
    SystemInit                 <span class="comment">// Set clock globals</span>
    main()
</div>

<p>
Built it. The binary grew from 10,504 bytes to 10,696 bytes (the MMU table
setup code). Moment of truth.
</p>

<h4>Victory #1: The MMU Fix Works</h4>

<p>
We loaded the threads binary via JTAG, resumed, waited five seconds, then
halted CPU0 to check where it was:
</p>

<pre>
> targets zynq.cpu0
> halt
> reg pc
pc: 0x00102204
> reg cpsr
cpsr: 0x6000001F    <span class="cmt">// SYS mode (0x1F) -- threads run in SYS mode!</span>
</pre>

<p>
SCTLR confirmed MMU was ON. The CPU was sitting in
<code>kernel::arch::exitCritical()</code>&mdash;meaning the scheduler was
running, threads were switching, the RTOS was <em>alive</em>. No more
alignment faults.
</p>

<p>
We immediately checked the peripheral state via JTAG to verify the full
system was configured:
</p>

<pre>
<span class="cmt"># Private Timer</span>
LOAD = 0x4F587 (324,999)    <span class="cmt">// 325 MHz / 325,000 = 1 ms tick. Correct!</span>
CTRL = 0x7                  <span class="cmt">// Enabled + Auto-reload + IRQ. Correct!</span>
Counter decrementing...      <span class="cmt">// Timer is running!</span>

<span class="cmt"># GIC</span>
CPU_CTRL  = 0x3             <span class="cmt">// CPU interface enabled. Correct!</span>
PRI_MASK  = 0xF8            <span class="cmt">// Priority mask. Correct!</span>
DIST_CTRL = 0x3             <span class="cmt">// Distributor enabled. Correct!</span>
EN_SET0   = 0x2000FFFF      <span class="cmt">// IRQ 29 (timer) + SGIs enabled. Correct!</span>
</pre>

<p>
Every single peripheral register was configured exactly as expected. Timer
ticking at 1 ms, GIC routing interrupts, context switching happening.
But... no serial output.
</p>

<h4>The UART ID Problem</h4>

<p>
The UART0 status register showed <code>SR = 0x0A</code> (TX FIFO empty,
RX FIFO empty). UART appeared enabled (<code>CR = 0x114</code>) but nothing
was being transmitted. We verified the serial link was good by manually
writing to the TX FIFO via JTAG:
</p>

<pre>
> mww 0xE0000030 0x54    <span class="cmt"># 'T'</span>
> mww 0xE0000030 0x45    <span class="cmt"># 'E'</span>
> mww 0xE0000030 0x53    <span class="cmt"># 'S'</span>
> mww 0xE0000030 0x54    <span class="cmt"># 'T'</span>
</pre>

<p>
"TEST" appeared on the serial console instantly. The UART hardware was fine.
The serial cable was fine. Something in our code was writing to the
<em>wrong UART</em>.
</p>

<p>
And then it clicked. The threads app (and all STM32 apps) use
<code>hal::UartId::Usart1</code> as the "primary serial port." On STM32,
Usart1 maps to USART1 peripheral. But on the Zynq HAL, the
<code>uartBase()</code> function only recognized <code>UartId::Uart0</code>
and <code>UartId::Uart1</code>&mdash;it sent <code>Usart1</code> to the
<em>default case</em>, which returned the UART1 base address
(<code>0xE0001000</code>). Our app was dutifully transmitting to
UART1, which isn't connected to anything on the PYNQ-Z2.
</p>

<p>
The fix was two lines:
</p>

<pre>
<span class="cmt">// Uart.cpp: uartBase()</span>
<span class="kw">case</span> hal::UartId::Uart0:
<span class="kw">case</span> hal::UartId::Usart1:   <span class="cmt">// Map STM32 "primary serial" to Zynq UART0</span>
    <span class="kw">return</span> kUart0Base;

<span class="cmt">// Rcc.cpp: rccEnableUartClock()</span>
<span class="kw">case</span> UartId::Uart0:
<span class="kw">case</span> UartId::Usart1:        <span class="cmt">// Same mapping for clock enable</span>
    reg(kSlcrBase + kAperClkCtrl) |= (<span class="num">1U</span> &lt;&lt; kUart0ClkBit);
</pre>

<p>
Two lines. Hours of debugging for two lines. That's embedded development.
</p>

<h4>The L2 Cache Nightmare: Why JTAG Reload Stopped Working</h4>

<p>
With the UART fix in place, we rebuilt and tried to JTAG-load the new binary.
Nothing. No serial output. CPU halted somewhere unexpected.
</p>

<p>
Wait&mdash;this worked five minutes ago! What changed?
</p>

<p>
Here's the thing about JTAG loading on a cached system: when OpenOCD writes
our binary to DDR via the debug port, it writes to <strong>physical DRAM</strong>.
But the CPU has the <strong>L2 cache (PL310)</strong> sitting between it and
DRAM. If the L2 cache holds code from the <em>previous</em> binary, the CPU
will keep fetching that stale cached code even though DRAM now has the new
binary.
</p>

<p>
On the first load, there was no previous binary cached. It worked. On the
second load, the L2 cache was full of code from the first run. The CPU
fetched the old code from L2, completely ignoring the new binary in DRAM.
</p>

<div class="diagram">
  <span class="label">The L2 Cache Problem</span>

  JTAG Load #1 (cold boot, caches empty):
    OpenOCD writes binary to DRAM  -->  CPU fetches from DRAM  -->  WORKS

  JTAG Load #2 (warm reload, caches hot):
    OpenOCD writes NEW binary to DRAM
    But L2 still has OLD binary cached
    CPU fetches from L2  -->  executes OLD code  -->  BROKEN

  The fix requires invalidating L2 BEFORE the CPU fetches any code.
  But our boot code that invalidates L2 is ALSO cached in L2.
  <span class="label">Catch-22.</span>
</div>

<p>
We added L2 cache invalidation to Startup.s:
</p>

<pre>
<span class="cmt">// Disable L2 cache (PL310 controller)</span>
ldr     r0, =<span class="num">0xF8F02100</span>     <span class="cmt">// L2C-310 Control Register</span>
mov     r1, #<span class="num">0</span>
str     r1, [r0]            <span class="cmt">// Disable L2</span>
dsb

<span class="cmt">// Invalidate all L2 ways</span>
ldr     r0, =<span class="num">0xF8F0277C</span>     <span class="cmt">// Invalidate by Way register</span>
mov     r1, #<span class="num">0xFF</span>           <span class="cmt">// All 8 ways</span>
str     r1, [r0]
<span class="num">3</span>:  ldr     r2, [r0]        <span class="cmt">// Poll until complete</span>
    tst     r2, #<span class="num">0xFF</span>
    bne     <span class="num">3</span>b
dsb
</pre>

<p>
But this didn't help for JTAG reload, because the boot code itself was cached
in L2 from the previous run. The old version of Startup.s (without the L2
invalidation) was what the CPU actually executed. Classic chicken-and-egg.
</p>

<h4>The Solution: Cache Invalidation via JTAG</h4>

<p>
The answer was to invalidate the caches <em>from OpenOCD</em>, before the CPU
even starts. We wrote a TCL script that does the full dance:
</p>

<pre>
<span class="cmt"># pynq_jtag_load.tcl -- load binary with full cache invalidation</span>
proc jtag_load {elf_path} {
    init
    targets zynq.cpu0
    halt
    sleep 200

    <span class="cmt"># Disable L1 D-cache and I-cache via SCTLR</span>
    set sctlr [zynq.cpu0 arm mrc 15 0 1 0 0]
    set sctlr [expr {$sctlr & ~(1 &lt;&lt; 0)}]    <span class="cmt">;# MMU off</span>
    set sctlr [expr {$sctlr & ~(1 &lt;&lt; 2)}]    <span class="cmt">;# D-cache off</span>
    set sctlr [expr {$sctlr & ~(1 &lt;&lt; 12)}]   <span class="cmt">;# I-cache off</span>
    zynq.cpu0 arm mcr 15 0 1 0 0 $sctlr

    <span class="cmt"># Invalidate L1 I-cache</span>
    zynq.cpu0 arm mcr 15 0 7 5 0 0

    <span class="cmt"># Invalidate L1 D-cache (all 4 ways x 256 sets)</span>
    for {set way 0} {$way &lt; 4} {incr way} {
        for {set set_idx 0} {$set_idx &lt; 256} {incr set_idx} {
            set val [expr {($way &lt;&lt; 30) | ($set_idx &lt;&lt; 5)}]
            zynq.cpu0 arm mcr 15 0 7 6 2 $val
        }
    }

    <span class="cmt"># Disable L2 cache (PL310)</span>
    mww 0xF8F02100 0x00000000
    sleep 10

    <span class="cmt"># Invalidate all L2 ways</span>
    mww 0xF8F0277C 0x000000FF
    sleep 50

    <span class="cmt"># Invalidate TLBs</span>
    zynq.cpu0 arm mcr 15 0 8 7 0 0

    echo "&gt;&gt;&gt; Caches invalidated. Loading ELF..."
    load_image $elf_path
    echo "&gt;&gt;&gt; Resuming at 0x00100000..."
    resume 0x00100000
}
</pre>

<p>
The script halts the CPU, disables all caches and MMU via CP15 coprocessor
writes through the JTAG debug interface, then invalidates every L1 cache line
(iterating all 4 ways x 256 sets), disables and invalidates the L2 PL310,
flushes the TLBs, and <em>only then</em> loads the new binary and resumes.
</p>

<h4>Victory #2: JTAG Reload Works</h4>

<pre>
$ openocd -f pynq_load.cfg -f pynq_jtag_load.tcl \
    -c "jtag_load build/app/threads/threads.elf"

&gt;&gt;&gt; Caches invalidated. Loading ELF...
&gt;&gt;&gt; Resuming at 0x00100000...
</pre>

<p>
Serial console:
</p>

<pre>
ms-os kernel starting
tick 0
mem ok pool=8/8 heap=0/16376
tick 1
tick 2
tick 3
...
</pre>

<p>
The RTOS was running via JTAG reload. Timer ticking. Three threads switching.
Memory management operational. Pool allocations working. Heap working. Every
single component that took months to build on Cortex-M was now running on
Cortex-A9.
</p>

<p>
That moment&mdash;seeing <code>"ms-os kernel starting"</code> on the serial
console from a completely different processor architecture&mdash;was one of the
most satisfying moments of the entire project. Months of careful abstraction,
the Arch.h interface, the platform-separated HAL, the build system that
selects the right files&mdash;it all paid off in that instant.
</p>

<h4>Victory #3: Clean SD Card Boot</h4>

<p>
To confirm the system worked without JTAG cache tricks, we built a BOOT.BIN
(Xilinx boot image: FSBL + our ELF) and booted from SD card. The FSBL does
a clean PS initialization, loads our binary to DDR, and jumps to it. No
stale caches, no u-boot residue.
</p>

<pre>
<span class="cmt"># boot.bif -- Xilinx Boot Image Format descriptor</span>
the_ROM_image:
{
    [bootloader]/path/to/zynq_fsbl.elf
    /path/to/threads.elf
}
</pre>

<pre>
$ bootgen -image boot.bif -o BOOT.BIN -w
</pre>

<p>
Copied BOOT.BIN to SD card, inserted into PYNQ-Z2, powered on. The serial
console showed the full RTOS output. Clean boot. No JTAG needed.
</p>

<h4>The Remaining Battles</h4>

<p>
The RTOS was running, but not perfectly. Two issues remained: thread state
corruption and UART output garbling. What followed was one of the most
satisfying debugging sessions of the entire project.
</p>

<h4>The Hunt for the Register Ghost</h4>

<p>
<strong>Symptom 1:</strong> When running two threads (LED + UART), the UART
thread's tick counter showed bizarre behavior. Instead of counting 0, 1, 2,
3..., the serial output flooded with two alternating values:
<code>"tick 30"</code> and <code>"tick 1"</code>, repeating thousands of times
per second. The counter was stuck.
</p>

<p>
The first experiment was to comment out the memThread and add critical sections
(<code>enterCritical</code>/<code>exitCritical</code>) around the UART writes
in the uartThread. This eliminated the garbled output (confirming the
interleaving theory), but the counter corruption remained.
</p>

<p>
<strong>Initial hypothesis:</strong> A scheduler race condition specific to
Cortex-A9. On Cortex-M, PendSV runs at the <em>lowest</em> interrupt priority,
creating a natural deferred context switch. On Cortex-A9, the SGI fires at
priority 0xF0 while the timer runs at 0xA0 (higher). Could the timer ISR
fire between <code>exitCritical()</code> and <code>triggerContextSwitch()</code>?
</p>

<p>
We dug deep into <code>Kernel.cpp</code>, <code>Scheduler.cpp</code>,
<code>ContextSwitch.s</code>, and <code>Thread.cpp</code>, tracing every
path through <code>yield()</code> and <code>sleep()</code>. The scheduler
race was real but would cause missed or double switches&mdash;not counter
corruption. Something else was at work.
</p>

<p>
<strong>The pivotal experiment:</strong> We switched the threads from
yield-based timing to <code>sleep()</code>-based timing:
</p>

<pre>
<span class="kw">void</span> <span class="fn">uartThread</span>(<span class="kw">void</span> *)
{
    std::uint32_t counter = <span class="num">0</span>;
    <span class="kw">while</span> (<span class="kw">true</span>)
    {
        <span class="cmt">// ... print counter ...</span>
        ++counter;
        kernel::<span class="fn">sleep</span>(<span class="num">1000</span>);
    }
}
</pre>

<p>
The output was devastating:
</p>

<pre>
tick 4176478465
tick 4176478465
tick 4176478465
tick 4176478465
</pre>

<p>
The counter was stuck at <strong>4,176,478,465</strong>. In hex:
<code>0xF8F00101</code>. That number looked familiar...
</p>

<p>
<code>0xF8F00100</code> is the <strong>GIC CPU interface base address</strong>.
And <code>0xF8F00101</code> is that value plus one&mdash;exactly what
<code>++counter</code> would produce if <code>counter</code> had been
overwritten with <code>0xF8F00100</code>.
</p>

<div class="highlight">
<strong>Smoking gun:</strong> <code>0xF8F00101 = GIC_CPU_BASE + 1</code>.
The compiler placed the thread's <code>counter</code> variable in register
<code>r4</code>. Something was writing the GIC base address into
<code>r4</code> during context switches.
</div>

<h4>Root Cause: Callee-Saved Register Clobbering</h4>

<p>
The bug was in <code>ContextSwitch.s</code>, the Cortex-A9 IRQ handler.
Here is the original code (simplified):
</p>

<pre>
<span class="fn">IRQ_Handler</span>:
    sub     lr, lr, #<span class="num">4</span>
    srsdb   sp!, #<span class="num">0x1F</span>
    cps     #<span class="num">0x1F</span>
    push    {r0-r3, r12, lr}

    <span class="cmt">/* Read GIC ICCIAR to get interrupt ID */</span>
    ldr     <span class="kw">r4</span>, =GIC_CPU_BASE       <span class="cmt">/* BUG: clobbers r4! */</span>
    ldr     <span class="kw">r5</span>, [<span class="kw">r4</span>, #ICCIAR_OFFSET]  <span class="cmt">/* BUG: clobbers r5! */</span>
    ...
    <span class="cmt">/* Context switch */</span>
    push    {r4-r11}     <span class="cmt">/* Saves WRONG r4/r5! */</span>
    str     sp, [r2, #<span class="num">0</span>]
</pre>

<p>
The IRQ handler used <code>r4</code> and <code>r5</code> for GIC register
access <em>before</em> the context switch saved them with
<code>push {r4-r11}</code>. On entry, <code>r0-r3</code> are saved, but
<code>r4-r11</code> belong to the <strong>interrupted thread</strong>.
They are callee-saved registers&mdash;the thread expects their values to be
preserved across function calls and interrupts.
</p>

<p>
By loading <code>GIC_CPU_BASE</code> into <code>r4</code>, the handler
destroyed whatever value the thread had in <code>r4</code>. When the context
switch later did <code>push {r4-r11}</code> to "save" the thread's state,
it saved the <em>handler's</em> <code>r4</code> (= <code>0xF8F00100</code>)
instead of the thread's <code>r4</code> (= <code>counter</code>). When the
thread was restored, its local variable <code>counter</code> contained the
GIC base address.
</p>

<p>
The reason <code>r4</code> and <code>r5</code> were used is that they are
callee-saved: their values survive across the C function calls
(<code>bl PrivateTimer_Handler</code>, <code>bl SysTick_Handler</code>) that
the IRQ handler makes. Using <code>r0-r3</code> for the GIC address would
lose them across those calls. The original author needed registers that
persisted&mdash;but those same registers belonged to the interrupted thread.
</p>

<div class="diagram">
<span class="label">BEFORE (buggy):</span>

Thread running with counter=42 in r4
    |
    v
IRQ fires -> hardware saves LR_irq, SPSR_irq
    |
    v
Handler:  push {r0-r3, r12, lr}   -- saves caller-saved
          ldr  r4, =0xF8F00100    -- OVERWRITES thread's r4 (was 42)
          ldr  r5, [r4, #0x0C]    -- OVERWRITES thread's r5
          ...bl PrivateTimer_Handler...
          ...bl SysTick_Handler...
    |
    v
Context switch:
          push {r4-r11}           -- saves r4=0xF8F00100, NOT 42!
          str  sp, [outgoing]
          ldr  sp, [incoming]
          pop  {r4-r11}           -- loads incoming thread
    |
    v
Later, original thread restored:
          pop  {r4-r11}           -- r4 = 0xF8F00100 (was 42!)
          counter is now 0xF8F00100
          ++counter => 0xF8F00101 = 4176478465
</div>

<h4>The Fix</h4>

<p>
The fix is simple but required understanding the constraint: between the
initial <code>push {r0-r3, r12, lr}</code> and the context switch's
<code>push {r4-r11}</code>, only <code>r0-r3</code> (already saved) and
the stack may be used. The ICCIAR value that must survive across C calls
goes on the stack instead:
</p>

<pre>
<span class="fn">IRQ_Handler</span>:
    sub     lr, lr, #<span class="num">4</span>
    srsdb   sp!, #<span class="num">0x1F</span>
    cps     #<span class="num">0x1F</span>
    push    {r0-r3, r12, lr}

    <span class="cmt">/* CRITICAL: Do NOT use r4-r11 before the context switch!
     * Those registers belong to the interrupted thread. */</span>

    ldr     r0, =GIC_CPU_BASE
    ldr     r1, [r0, #ICCIAR_OFFSET]
    push    {r1}                <span class="cmt">/* Save ICCIAR on stack */</span>

    ubfx    r0, r1, #<span class="num">0</span>, #<span class="num">10</span>   <span class="cmt">/* Extract IRQ ID */</span>
    cmp     r0, #PRIVATE_TIMER_IRQ
    beq     .Ltimer_irq
    ...

.Lirq_eoi:
    pop     {r1}                <span class="cmt">/* Restore ICCIAR from stack */</span>
    ldr     r0, =GIC_CPU_BASE
    str     r1, [r0, #ICCEOIR_OFFSET]

    <span class="cmt">/* Now r4-r11 are still the interrupted thread's values */</span>
    push    {r4-r11}            <span class="cmt">/* Correct! */</span>
    ...
</pre>

<p>
After the fix, serial output was perfect:
</p>

<pre>
$ python3 -c "import serial; s = serial.Serial('/dev/ttyUSB1', 115200, timeout=15); ..."
ms-os kernel starting
tick 0
tick 1
tick 2
tick 3
tick 4
mem ok pool=8/8 heap=0/16376
tick 5
tick 6
tick 7
tick 8
tick 9
mem ok pool=8/8 heap=0/16376
tick 10
...
</pre>

<p>
Monotonically incrementing tick counter. Memory tests passing every 5 seconds.
No garbled output. All three threads running correctly.
</p>

<h4>Thread-Safe UART</h4>

<p>
With the context switch fixed, the UART thread safety was straightforward.
Each platform's <code>uartWrite()</code> now saves the interrupt state,
disables IRQs for the duration of the write, and restores the previous state:
</p>

<pre>
<span class="cmt">/* Zynq (Cortex-A9): save/restore CPSR */</span>
<span class="kw">void</span> <span class="fn">uartWrite</span>(UartId id, <span class="kw">const</span> <span class="kw">char</span> *data, std::size_t length)
{
    std::uint32_t saved = <span class="fn">disableIrq</span>();  <span class="cmt">// mrs cpsr + cpsid i</span>
    <span class="kw">for</span> (std::size_t i = <span class="num">0</span>; i &lt; length; ++i)
        <span class="fn">uartPutChar</span>(id, data[i]);
    <span class="fn">restoreIrq</span>(saved);                   <span class="cmt">// msr cpsr_c</span>
}

<span class="cmt">/* STM32 (Cortex-M): save/restore PRIMASK */</span>
<span class="kw">void</span> <span class="fn">uartWrite</span>(UartId id, <span class="kw">const</span> <span class="kw">char</span> *data, std::size_t length)
{
    std::uint32_t saved = <span class="fn">disableIrq</span>();  <span class="cmt">// mrs primask + cpsid i</span>
    <span class="kw">for</span> (std::size_t i = <span class="num">0</span>; i &lt; length; ++i)
        <span class="fn">uartPutChar</span>(id, data[i]);
    <span class="fn">restoreIrq</span>(saved);                   <span class="cmt">// msr primask</span>
}
</pre>

<p>
This makes each <code>uartWriteString()</code> call atomic. The application
still uses critical sections around multi-call sequences (e.g.,
<code>"tick " + number + "\r\n"</code>) to prevent interleaving between
calls, but the HAL itself is now safe for concurrent access.
</p>

<div class="lesson">
<strong>Lesson 5:</strong> On Cortex-A9, the IRQ handler runs in the
interrupted thread's register context. Registers <code>r4-r11</code> are
<em>not free scratch space</em>&mdash;they belong to the interrupted thread
and must not be touched between entry and the context switch save. On
Cortex-M, PendSV has the same constraint, but the hardware exception frame
automatically saves <code>r0-r3, r12, LR, PC, xPSR</code>. On Cortex-A9,
you must be even more disciplined because the save is entirely manual.
</div>

<div class="lesson">
<strong>Lesson 5a:</strong> When a variable takes on an impossible value,
convert it to hex. <code>4176478465</code> means nothing.
<code>0xF8F00101</code> is immediately recognizable as a hardware register
address (GIC CPU interface + 1). The hex representation turned a mystery
into a smoking gun.
</div>

<h3>The Debugging Lessons</h3>

<p>
The PYNQ-Z2 bringup taught us more about ARM architecture in a few sessions
than months of reading reference manuals. Every bug was a lesson:
</p>

<div class="lesson">
<strong>Lesson 1:</strong> Linux leaves extensive hardware state. The GIC has
pending timer interrupts that fire <em>before your first instruction executes</em>.
You must disable the GIC and clear all pending IRQs via OpenOCD before resuming.
</div>

<div class="lesson">
<strong>Lesson 2:</strong> CPU1's MMU interferes with debug memory access.
Even with CPU0's MMU disabled, OpenOCD routes some reads through CPU1.
Disable MMU on <em>both</em> CPUs before any bare-metal work.
</div>

<div class="lesson">
<strong>Lesson 3:</strong> Always cross-reference register definitions against
the TRM. We spent hours debugging silent UART output because our Control
Register bit definitions were wrong&mdash;we were asserting STARTBRK
(forcing TXD permanently LOW) instead of resetting the TX FIFO.
</div>

<div class="lesson">
<strong>Lesson 4:</strong> WFE on Cortex-A9 can gate the debug clock domain,
making the CPU unreachable via JTAG. Use infinite <code>b .</code> loops
instead of WFE during early bringup.
</div>

<div class="lesson">
<strong>Lesson 6:</strong> JTAG reads bypass the CPU's data cache. If your
code uses write-back caching (which it should, for performance), variables
read via JTAG will show stale DRAM values, not the current values in the
D-cache. Don't trust JTAG memory reads for variables that are actively being
updated by the CPU. Use direct register reads (via CP15 MCR/MRC through
OpenOCD) instead.
</div>

<div class="lesson">
<strong>Lesson 7:</strong> L2 cache invalidation is mandatory for JTAG binary
reload, but the boot code that does the invalidation is <em>itself</em>
cached from the previous run. You must invalidate from outside the CPU
(via the JTAG debug interface) before loading new code.
</div>

<div class="lesson">
<strong>Lesson 8:</strong> When bringing up a new architecture, verify
each subsystem independently. Write "TEST" to the UART FIFO via JTAG
to confirm the serial link works before debugging your UART driver code.
Check GIC, timer, and MMU registers via JTAG independently. Don't assume
the whole system is broken just because you see no output&mdash;isolate
the problem.
</div>

<h3>Where We Stand</h3>

<p>
The PYNQ-Z2 port is fully operational. The r4/r5 register clobbering bug
is fixed, UART output is thread-safe at the HAL level, and all three
threads run correctly on Cortex-A9. The full RTOS&mdash;scheduler, context
switching, memory management, crash dumps&mdash;works on all three hardware
targets. The architecture abstraction delivers on its promise: the same
kernel source code, the same application code, builds and runs on Cortex-M3,
Cortex-M4, and Cortex-A9 by selecting the target at build time.
</p>

<div class="highlight">
<strong>Status after Phase 4:</strong> ms-os runs on <strong>three hardware
targets</strong> spanning two ARM architecture families (ARMv7-M and ARMv7-A),
with <strong>136 host unit tests</strong>, three cross-compiled applications,
thread-safe UART, and a fully operational JTAG development workflow. All bugs
resolved. Binary size for the full RTOS with three threads:
<strong>10,740 bytes</strong> of code on Cortex-A9.
</div>

<!-- ============================================================ -->
<!--                     CHAPTER 6                                -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 6</span>
  Talking Between Threads (Phase 5)
</h2>

<div class="epigraph">
  "The art of programming is the art of organizing complexity."
  <div class="attribution">&mdash; Edsger Dijkstra</div>
</div>

<p>
A microkernel without IPC is a fortress without doors. We had built
walls (privilege separation, MPU protection), we had built rooms (threads,
stacks, priorities), we had built hallways (the scheduler, context
switching). But the rooms could not talk to each other. Every thread was
an island.
</p>

<p>
The microkernel promise&mdash;that drivers and services live outside the
kernel, communicating through well-defined channels instead of sharing
global state&mdash;was still theoretical. We had the isolation, but we
had no communication. Phase 5 was about building the doors.
</p>

<h3>The Design Space</h3>

<p>
Before writing a single line of code, we sat down with the three
canonical IPC models and asked: which one fits a microkernel RTOS on a
Cortex-M with 128 KB of SRAM?
</p>

<p>
<strong>Shared memory</strong> is the fastest option. Two threads agree
on a memory region and read/write directly. But who owns that memory? Who
manages the locks? We had just spent Phase 3 building an MPU to
<em>prevent</em> exactly this kind of Wild West memory access. Shared
memory works beautifully when both sides are trusted and cooperative. In
a microkernel where the entire point is isolation, it is the wrong
abstraction.
</p>

<p>
<strong>Pipes and channels</strong> are flexible. You can send arbitrary
streams of bytes, buffer them, apply flow control. But pipes need kernel
buffers. They need allocation. They need a whole subsystem to manage
reader/writer state, EOF conditions, and partial reads. On a system where
the total heap is 16 KB, a pipe subsystem felt like building a highway
when we needed a footpath.
</p>

<p>
<strong>Message passing</strong>&mdash;Minix-style send/receive/reply&mdash;was
the clear winner. A client sends a fixed-size message to a server. The
client blocks. The server receives the message, processes it, and replies.
The client wakes with its answer. No shared state, no races, no ownership
ambiguity. The protocol is synchronous by default: a client knows that
when <code>messageSend()</code> returns, the server has already processed
its request. This maps perfectly to the RPC pattern that user-space
drivers need to service application requests.
</p>

<div class="key-decision">
<strong>Key Decision:</strong> Minix-style synchronous message passing.
The client-server RPC pattern (send, block, receive, process, reply, wake)
is the primary IPC primitive. No shared memory regions, no kernel pipe
buffers, no variable-length allocations. Each message is a fixed-size
struct that fits in a cache line.
</div>

<h3>The 64-Byte Constraint</h3>

<p>
The next question was: how big is a message? This is one of those
decisions that sounds trivial but reverberates through the entire system.
Too small, and you cannot pass enough data in a single call. Too large,
and you waste memory in every mailbox slot. We did the napkin math.
</p>

<p>
The header needs to carry enough information for the kernel to route the
message and for the receiver to dispatch it. We settled on 16 bytes:
</p>

<div class="diagram">
  <span class="label">Message Header (16 bytes)</span>

  Offset  Size  Field
  ------  ----  -----
    0       4   sender       <span class="comment">-- ThreadId of the sending thread</span>
    4       4   type         <span class="comment">-- cycleType (send, reply, notify)</span>
    8       2   methodId     <span class="comment">-- which RPC method is being called</span>
   10       2   serviceId    <span class="comment">-- which service (FNV-1a hash of name)</span>
   12       2   status       <span class="comment">-- return code for replies</span>
   14       2   payloadSize  <span class="comment">-- how many of the 48 payload bytes are used</span>
</div>

<p>
That leaves 48 bytes of inline payload. Is 48 bytes enough? For the
typical microkernel RPC&mdash;open a file, read a sensor, configure a
peripheral&mdash;the arguments are a handful of integers, a short string,
or a small struct. Forty-eight bytes covers the vast majority of cases.
For the rare large transfer, the payload can carry a pointer to a shared
buffer (negotiated at a higher protocol level).
</p>

<p>
Why 64 bytes total? Because it fits in a single cache line on both
Cortex-M (if the chip has a cache) and Cortex-A9. It avoids heap
allocation entirely. And it keeps the mailbox small: each thread gets
a 4-slot ring buffer, so the mailbox costs 4 x 64 = 256 bytes per
thread. For 8 threads, that is 2,048 bytes&mdash;about 1.6% of our
128 KB SRAM.
</p>

<p>
But the real elegance was a trick we borrowed from the IDL code
generator. For every RPC method, the generator emits a
<code>static_assert</code> that the serialized arguments fit within 48
bytes:
</p>

<pre>
<span class="cmt">// Generated by ipcgen -- compile-time payload overflow check</span>
<span class="kw">static_assert</span>(<span class="kw">sizeof</span>(EchoArgs) <= <span class="num">48</span>,
    <span class="str">"Echo::echo payload exceeds 48-byte limit"</span>);
</pre>

<p>
Payload overflow is a compile error, not a runtime crash. If a developer
adds a field that pushes the argument struct past 48 bytes, the build
fails with a clear message pointing at the exact method. No testing
required&mdash;the type system catches it before a single byte hits the
wire.
</p>

<h3>The Blocking Question</h3>

<p>
The hardest design question was deceptively simple: what happens when
the mailbox is full?
</p>

<p>
If <code>messageSend()</code> blocks when the target's mailbox has no
free slots, you get clean RPC semantics. The client waits, the server
processes one message and frees a slot, the client wakes and sends. It
is simple and correct. But there is a dark side: if the server thread
is dead or starved, the client blocks forever. In a hard real-time
system, "forever" is not an acceptable timeout.
</p>

<p>
If <code>messageSend()</code> returns an error immediately when the
mailbox is full, you get ISR safety and bounded latency. But now the
caller has to handle the error, retry, or drop the message. Every
call site needs error handling. The simplicity of synchronous RPC
dissolves into a puddle of retry loops.
</p>

<p>
We chose both. <code>messageSend()</code> blocks. <code>messageTrySend()</code>
returns <code>kIpcErrFull</code> immediately. Same dilemma on the
receive side: <code>messageReceive()</code> blocks when the mailbox is
empty (the server pattern&mdash;wait for work), and
<code>messageTryReceive()</code> returns <code>kIpcErrEmpty</code>
(the polling pattern&mdash;check for work, then do something else).
Let the caller choose their poison.
</p>

<p>
The blocking implementation reused the exact same pattern as mutex and
semaphore from Phase 2: enter critical section, insert thread into a
wait queue on the target mailbox, mark the thread as blocked, switch
context, exit critical section, trigger context switch. When the
server processes a message and frees a slot, it dequeues the first
waiting sender and marks it ready. The scheduler does the rest.
</p>

<p>
For interrupt-driven scenarios where even trying to block would be
fatal, we added <strong>async notifications</strong>: a per-thread
32-bit bitmask that can be atomically OR'd from any context, including
ISRs. <code>messageNotify()</code> sets bits;
<code>messageCheckNotify()</code> reads and clears them. No locks, no
mailbox slots consumed, no possibility of blocking. A driver ISR can
notify a service thread in constant time with zero allocation.
</p>

<h3>Building the Tool to Build the Tool</h3>

<p>
With the IPC primitives in place, we hand-wrote the echo service. The
client packs a string into the 48-byte payload, sets the sizes, calls
<code>messageSend()</code>, waits for the reply, unpacks the response.
The server loops on <code>messageReceive()</code>, copies the payload
into the reply, calls <code>messageReply()</code>. It worked. It was
also tedious.
</p>

<p>
Every service would need the same boilerplate: serialize arguments into
the payload, deserialize on the other side, dispatch to the right method
based on <code>methodId</code>, pack the return values. Hand-writing
this for a dozen services would be error-prone and mind-numbing. What
if we described the service in a file and generated all the boilerplate?
</p>

<p>
We already had a lexer and parser from <strong>ms-ipc</strong>, the
sibling IPC library we built for Linux user-space. The lexer tokenizes
an IDL file. The parser builds an AST of services, methods, and types.
All we needed was a new <em>emitter</em>&mdash;one that generates
embedded-friendly C++ instead of the Linux shared-memory transport code
that ms-ipc targets.
</p>

<p>
The new <code>embedded_emitter.py</code> generates four files per
service:
</p>

<pre>
<span class="cmt">// EchoService.idl -- the service definition</span>
service Echo {
    method echo(data: bytes) -> (data: bytes);
    notification overflow;
}
</pre>

<pre>
<span class="cmt">// Generated: EchoClient.h + EchoClient.cpp</span>
<span class="cmt">//   - Typed RPC stub: Echo::echo(data) -> data</span>
<span class="cmt">//   - Packs args into payload, calls messageSend, unpacks reply</span>
<span class="cmt">//   - static_assert on every method's payload size</span>

<span class="cmt">// Generated: EchoServer.h + EchoServer.cpp</span>
<span class="cmt">//   - Dispatch loop: messageReceive -> switch(methodId) -> handleXxx</span>
<span class="cmt">//   - Virtual methods for each IDL method (developer overrides)</span>
<span class="cmt">//   - messageReply with return values packed into payload</span>
</pre>

<p>
Service IDs are FNV-1a hashes of the service name, giving stable 32-bit
identifiers without a central registry. Method IDs are sequential within
each service. The generated code handles all serialization, dispatch,
and reply plumbing. The developer writes one <code>.idl</code> file and
overrides the handler methods. The tool built the tool that built the
service.
</p>

<p>
Notification methods in the IDL translate to two flavors: parameterless
notifications use the lightweight <code>messageNotify()</code> bitmask
path, while notifications with a payload use
<code>messageTrySend()</code> since they originate from ISR-like
contexts where blocking is not permitted.
</p>

<h3>First Message</h3>

<p>
The moment of truth. The echo server starts on thread 1, priority 10.
The echo client starts on thread 2, priority 15. The client calls
<code>messageSend(server=1, msg="hello")</code>. Here is what happens,
step by step:
</p>

<div class="diagram">
  <span class="label">IPC Round Trip: echo("hello")</span>

  echo-cli (thread 2, pri 15)          echo-srv (thread 1, pri 10)
  ----------------------------          ----------------------------
  messageSend(dest=1, "hello")
    |
    +-> copy msg to server mailbox
    +-> server has waiter? YES
    |     -> wake echo-srv (Ready)
    +-> client blocks (Blocked)
    +-> context switch
                                        messageReceive(&msg)
                                          |
                                          +-> msg.payload = "hello"
                                          +-> process: reply = "hello"
                                          |
                                        messageReply(dest=2, "hello")
                                          |
                                          +-> copy reply to client mailbox
                                          +-> wake echo-cli (Ready)
                                          +-> context switch
  messageSend returns!
    |
    +-> reply.payload = "hello"
    +-> round trip complete
</div>

<p>
We watched it happen on the serial console. The client printed the
reply. Five characters, echoed back through two context switches, a
mailbox enqueue, a dispatch loop, and a reply. The threads were talking.
</p>

<p>
The IPC demo application launched all the pieces together: echo server,
echo client, LED blinker, and the shell thread. Four threads,
communicating through messages, scheduled by priority, all on a chip
with 128 KB of RAM. We typed <code>ps</code> in the shell and watched
the thread states change in real time as the echo client sent requests
and blocked waiting for replies. It was the first time ms-os felt like
a real operating system rather than a collection of kernel primitives.
</p>

<div class="highlight">
<strong>Status after Phase 5:</strong> ms-os has kernel IPC with synchronous
send/receive/reply, async notifications (32-bit bitmask), both blocking and
non-blocking variants of every operation, a Python IDL code generator
(ipcgen, 40 new tests), and a working echo service demo. Memory budget:
~3.4 KB total (2.2 KB for 8 mailboxes + 1.2 KB code). Zero heap
allocations in the IPC path.
</div>

<p>
For the complete message struct layout and mailbox ring buffer design,
see the <a href="architecture.html#ipc">Architecture Guide</a>.
</p>

<!-- ============================================================ -->
<!--                     CHAPTER 7                                -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 7</span>
  Drawing the Line (Phase 6)
</h2>

<div class="epigraph">
  "Trust, but verify."
  <div class="attribution">&mdash; Russian proverb (popularized by Ronald Reagan)</div>
</div>

<p>
Every operating system eventually has to answer the question: what
happens when code you do not fully trust wants to use the kernel? On
Cortex-M, the answer lives in a single bit of the CONTROL register.
Setting it was the easy part. Surviving the consequences was not.
</p>

<p>
Until Phase 6, every thread in ms-os ran in privileged mode. Any thread
could poke any peripheral register, disable interrupts globally, or
overwrite the scheduler's data structures. The MPU existed, but it was
a suggestion rather than a wall&mdash;privileged code can bypass it
at will. For a microkernel that aspires to run untrusted user-space
services, this was not just inelegant. It was dangerous.
</p>

<h3>The Privilege Boundary</h3>

<p>
On ARM Cortex-M, the distinction between privileged and unprivileged
code comes down to one register and two bits:
</p>

<div class="diagram">
  <span class="label">CONTROL Register (Cortex-M4)</span>

  +------+--------+--------------------------------------------+
  | Bit  | Field  | Description                                |
  +------+--------+--------------------------------------------+
  |  1   | SPSEL  | 0 = MSP (Main Stack), 1 = PSP (Process)   |
  |  0   | nPRIV  | 0 = Privileged, 1 = Unprivileged           |
  +------+--------+--------------------------------------------+

  Privileged thread:    CONTROL = 0b10  (PSP, privileged)
  Unprivileged thread:  CONTROL = 0b11  (PSP, unprivileged)
</div>

<p>
We were already using SPSEL=1 to run threads on the Process Stack
Pointer (PSP). The kernel and exception handlers use the Main Stack
Pointer (MSP). That separation was established in Phase 1. Now we needed
to flip one more bit: nPRIV.
</p>

<p>
What changes when nPRIV=1? Everything that matters. The MPU is enforced
strictly&mdash;unprivileged code cannot access any region marked as
privileged-only. Peripheral registers (mapped in the 0x40000000 range on
STM32) are behind the MPU's peripheral region, which is configured as
privileged read/write only. An unprivileged thread that tries to toggle
a GPIO pin gets a MemManage fault. An unprivileged thread that tries to
disable interrupts with <code>cpsid i</code> gets a UsageFault. The
hardware enforces what the kernel dictates.
</p>

<p>
The TCB extension was minimal: one boolean field,
<code>privileged</code>, at offset 44 (after <code>mpuStackRasr</code>
at offset 40). During context switch, PendSV reads this field from the
incoming thread's TCB and writes the appropriate CONTROL value:
</p>

<pre>
<span class="cmt">// In PendSV_Handler (assembly)</span>
ldr   r2, [r1, #<span class="num">44</span>]      <span class="cmt">// r2 = tcb->privileged</span>
cmp   r2, #<span class="num">0</span>
ite   ne
movne r3, #<span class="num">0x02</span>          <span class="cmt">// privileged:   SPSEL=1, nPRIV=0</span>
moveq r3, #<span class="num">0x03</span>          <span class="cmt">// unprivileged: SPSEL=1, nPRIV=1</span>
msr   CONTROL, r3
isb                        <span class="cmt">// flush pipeline after CONTROL write</span>
</pre>

<p>
The ISB (Instruction Synchronization Barrier) after the MSR is critical.
Without it, the pipeline might execute the next few instructions under
the old privilege level before the CONTROL write takes effect. On
Cortex-M4, this is a documented requirement&mdash;the Architecture
Reference Manual is explicit about it. We had read enough ARM errata
sheets by this point to take pipeline synchronization seriously.
</p>

<p>
The <code>createThread()</code> API gained an optional parameter that
defaults to <code>privileged=true</code>. Every existing thread
continued to run exactly as before. Backward compatibility was
non-negotiable&mdash;we could not break the echo server, the LED
blinker, or the shell. Only threads explicitly created as unprivileged
would get the nPRIV treatment.
</p>

<h3>The Syscall Table</h3>

<p>
An unprivileged thread cannot call kernel functions directly. The MPU
would fault on the first access to a kernel data structure in SRAM
(region configured as privileged read/write only). Instead, the thread
executes an <code>SVC</code> (Supervisor Call) instruction, which traps
synchronously into the SVC_Handler running in Handler mode&mdash;always
privileged, always on the MSP, always able to touch kernel memory.
</p>

<p>
Why SVC? On Cortex-M, it is the only synchronous trap instruction.
<code>SVC #N</code> immediately enters the exception handler with the
exception number baked into the instruction encoding. The result can be
placed in r0 before returning. No round-trips, no polling, no
asynchronous notification. The thread traps, the kernel does the work,
the thread resumes with the answer.
</p>

<p>
The SVC number extraction is a beautiful piece of ARM convention. The
SVC_Handler reads the stacked PC (which points to the instruction
<em>after</em> the SVC), subtracts 2 to find the SVC opcode itself,
loads the halfword, and masks out the low byte&mdash;that is the
immediate value N from <code>SVC #N</code>:
</p>

<pre>
<span class="cmt">// SVC_Handler -- extract SVC number from faulting instruction</span>
tst    lr, #<span class="num">4</span>           <span class="cmt">// which stack was active?</span>
ite    eq
mrseq  r0, MSP          <span class="cmt">// handler was using MSP</span>
mrsne  r0, PSP          <span class="cmt">// thread was using PSP</span>
ldr    r1, [r0, #<span class="num">24</span>]    <span class="cmt">// r1 = stacked PC</span>
ldrb   r1, [r1, #-<span class="num">2</span>]    <span class="cmt">// r1 = SVC number (low byte of SVC opcode)</span>
</pre>

<p>
We defined 24 system calls (SVC 0 through SVC 23). SVC 0 is special:
it launches the first thread and never returns. SVC 1 through 23 cover
the complete kernel API:
</p>

<table>
<tr><th>SVC #</th><th>Function</th><th>SVC #</th><th>Function</th></tr>
<tr><td>1</td><td>yield</td><td>13</td><td>semaphoreCreate</td></tr>
<tr><td>2</td><td>sleep</td><td>14</td><td>messageSend</td></tr>
<tr><td>3</td><td>tickCount</td><td>15</td><td>messageReceive</td></tr>
<tr><td>4</td><td>mutexCreate</td><td>16</td><td>messageReply</td></tr>
<tr><td>5</td><td>mutexDestroy</td><td>17</td><td>messageTrySend</td></tr>
<tr><td>6</td><td>mutexLock</td><td>18</td><td>messageTryReceive</td></tr>
<tr><td>7</td><td>mutexUnlock</td><td>19</td><td>messageNotify</td></tr>
<tr><td>8</td><td>mutexTryLock</td><td>20</td><td>messageCheckNotify</td></tr>
<tr><td>9</td><td>semaphoreWait</td><td>21</td><td>heapAlloc</td></tr>
<tr><td>10</td><td>semaphoreSignal</td><td>22</td><td>heapFree</td></tr>
<tr><td>11</td><td>semaphoreTryWait</td><td>23</td><td>heapAvailable</td></tr>
<tr><td>12</td><td>semaphoreDestroy</td><td>&nbsp;</td><td>&nbsp;</td></tr>
</table>

<p>
The C++ dispatch function <code>svcDispatch()</code> receives the syscall
number and a pointer to the exception frame, extracts arguments from the
stacked r0-r3, calls the appropriate kernel function, and writes the
return value back to the stacked r0 so the caller sees it when it
resumes.
</p>

<p>
On the caller side, the inline assembly wrappers are a thing of beauty.
The register constraint syntax maps C++ arguments directly to ARM
registers without any memory round-trip:
</p>

<pre>
<span class="cmt">// kernel::user::sleep() -- SVC wrapper</span>
<span class="kw">inline</span> <span class="kw">void</span> <span class="fn">sleep</span>(<span class="kw">uint32_t</span> ticks)
{
    <span class="kw">register</span> <span class="kw">uint32_t</span> r0 <span class="kw">__asm</span>(<span class="str">"r0"</span>) = ticks;
    <span class="kw">__asm</span> <span class="kw">volatile</span>(<span class="str">"svc %1"</span> : <span class="str">"+r"</span>(r0) : <span class="str">"I"</span>(kSleep) : <span class="str">"memory"</span>);
}
</pre>

<p>
The <code>"I"</code> constraint means the SVC number is an immediate
constant&mdash;it gets baked into the instruction encoding at compile
time. No table lookup, no function pointer, no indirect call. On ARM,
<code>kernel::user::sleep(100)</code> compiles to exactly two
instructions: <code>mov r0, #100</code> and <code>svc #2</code>. On
the host build (x86), the same header compiles to a direct call to
<code>kernel::sleep(100)</code>&mdash;no SVC instruction exists on x86.
Same source code, different backends, zero overhead on either platform.
</p>

<div class="key-decision">
<strong>Key Decision:</strong> Dual-mode syscall wrappers. On ARM,
<code>kernel::user::foo()</code> compiles to an SVC trap. On x86,
it compiles to a direct function call. Application code includes one
header and works on both the target and the test host without any
<code>#ifdef</code>.
</div>

<h3>First Flash</h3>

<p>
We created an unprivileged echo client thread. One line changed in the
application code: <code>createThread("echo-cli", echoClientMain, arg,
512, 15, false)</code>&mdash;the final <code>false</code> marking it
as unprivileged. The client used <code>kernel::user::sleep()</code> and
<code>kernel::user::messageSend()</code> instead of the direct kernel
calls. Flash. Boot. The LED blinked. The server printed "Echo server
started." The shell responded to keystrokes.
</p>

<p>
And the echo client... did nothing.
</p>

<h3>The Silent Failure</h3>

<p>
No crash. No fault. No error message on the serial console. The echo
client simply sat there, silent, as if it had never been created. The
server thread waited patiently for messages that never arrived. The
shell showed the client as "Ready"&mdash;it was running, it was being
scheduled, it was consuming its time slice. But it was not communicating.
</p>

<p>
This was the kind of bug that keeps you up at night. A crash is a gift.
A crash gives you a fault address, a register dump, a stack trace, a
thread ID. A crash points at the crime scene and says "look here." A
silent failure gives you nothing. The system appears to work. The only
evidence that something is wrong is the absence of something that should
be present.
</p>

<h4>Adding Instrumentation</h4>

<p>
We added debug prints at every stage of the IPC path. The client calls
<code>kernel::user::messageSend()</code>. The SVC trap fires. We land
in <code>svcDispatch()</code>. The dispatch function identifies SVC #14
as <code>messageSend</code>, extracts the arguments from the stacked
registers, and calls <code>kernel::messageSend()</code>.
</p>

<p>
And then <code>kernel::messageSend()</code> returns. Immediately.
Return code: <code>kIpcErrInIsr</code>.
</p>

<p>
"In an ISR? The client is a thread!"
</p>

<h4>The Logic Chain</h4>

<p>
We traced the logic chain, instruction by instruction, register by
register, until we found the culprit. Here is the complete path from
the echo client's perspective:
</p>

<div class="diagram">
  <span class="label">The Silent Failure: IPC from Unprivileged Thread</span>

  echo-cli (unprivileged, Thread mode)
    |
    kernel::user::messageSend(dest=1, msg)
    |
    svc #14                          <span class="comment">-- trap to Handler mode</span>
    |
    v
  SVC_Handler (Handler mode, VECTACTIVE = 11)
    |
    svcDispatch(14, frame)
      |
      kernel::messageSend(dest=1, msg)
        |
        <span class="label">inIsrContext()</span>                <span class="comment">-- safety check: can we block?</span>
          |
          SCB->ICSR & 0x1FF          <span class="comment">-- read VECTACTIVE field</span>
          = 11                        <span class="comment">-- SVCall exception number!</span>
          return <span class="label">true</span>                <span class="comment">-- "I am in an ISR"</span>
        |
        "Cannot block in ISR context"
        return kIpcErrInIsr           <span class="comment">-- silently refuses to send</span>
    |
    svcDispatch writes kIpcErrInIsr to stacked r0
    |
    v
  echo-cli resumes
    |
    return code = kIpcErrInIsr        <span class="comment">-- but nobody checks it</span>
    |
    loop: try again... same result... forever
</div>

<p>
There it was. The SVC handler IS an ISR. On Cortex-M, the SVC
instruction traps into Handler mode. The ICSR register's VECTACTIVE
field becomes nonzero&mdash;exception number 11, which is the SVCall
exception. From the hardware's perspective, we are inside an exception
handler. The CPU is in Handler mode. The stack pointer is the MSP.
Every architectural marker says "this is an interrupt service routine."
</p>

<p>
And every responsible kernel function in ms-os checks
<code>inIsrContext()</code> and refuses to block when it returns true.
We wrote those checks ourselves, in Phase 2, because blocking inside
an ISR is one of the cardinal sins of embedded programming. It leads
to deadlock, priority inversion, and system hangs. So
<code>kernel::sleep()</code> returns immediately if called from ISR
context. <code>kernel::messageSend()</code> returns
<code>kIpcErrInIsr</code>. <code>kernel::mutexLock()</code> returns
false. Every single blocking syscall politely declined to do its job.
</p>

<h4>The Philosophical Problem</h4>

<p>
This was not a simple coding bug. It was a <em>conceptual</em> conflict
between two correct abstractions.
</p>

<p>
The hardware says: "SVC_Handler is an exception handler. It runs in
Handler mode. VECTACTIVE is nonzero. You are in an ISR."
</p>

<p>
The kernel says: "You must never block inside an ISR. That way lies
deadlock and priority inversion."
</p>

<p>
Both are correct. But SVC dispatch is not <em>really</em> an ISR. It is
the kernel acting on behalf of a thread. The thread wants to sleep. The
thread wants to send a message. The SVC handler is just the
<em>mechanism</em> by which an unprivileged thread asks the kernel to do
these things. Semantically, we are in thread context&mdash;the operation
was initiated by a thread, will return to a thread, and should have the
blocking semantics of a thread. Mechanically, we are in Handler
mode&mdash;the CPU's execution mode after taking an exception.
</p>

<p>
The kernel's ISR guard was too aggressive. It could not distinguish
between "we are in a timer ISR and must not block" and "we are in an
SVC handler performing a syscall on behalf of a thread and blocking is
exactly what the thread asked us to do."
</p>

<h4>The Fix</h4>

<p>
The solution was three lines of code and one global flag:
</p>

<pre>
<span class="cmt">// Arch.cpp</span>
<span class="kw">volatile</span> <span class="kw">bool</span> g_inSyscall = <span class="kw">false</span>;

<span class="kw">bool</span> <span class="fn">inIsrContext</span>()
{
    <span class="kw">if</span> (g_inSyscall) <span class="kw">return</span> <span class="kw">false</span>;
    <span class="kw">return</span> (reg(kScbIcsr) & <span class="num">0x1FF</span>u) != <span class="num">0</span>;
}
</pre>

<p>
<code>svcDispatch()</code> sets <code>g_inSyscall = true</code> before
calling any kernel function, and clears it after. When
<code>inIsrContext()</code> sees VECTACTIVE=11 (SVCall) but
<code>g_inSyscall</code> is true, it returns false. "You are in Handler
mode, but you are executing on behalf of a thread. Blocking is
permitted."
</p>

<p>
Three lines of change. One flag. The entire syscall interface came alive.
</p>

<p>
The echo client sent its first message. The server received it. The
reply came back. Five characters, round-tripped through an SVC trap, a
privilege escalation, a mailbox enqueue, a context switch, a dispatch
loop, a reply, and a privilege de-escalation. The unprivileged thread
was talking to the kernel, through the kernel, to another thread.
</p>

<div class="lesson">
<strong>Lesson:</strong> The hardest bugs are not crashes. Crashes leave
evidence&mdash;fault addresses, register dumps, stack traces. The hardest
bugs are silent failures where everything appears to work but nothing
actually happens. The IPC call "succeeded" at every layer except the one
that mattered. <code>messageSend()</code> returned an error code, but the
echo client's retry loop just called it again, and again, and again. No
crash. No fault. Just an unprivileged thread screaming into the void.
</div>

<h4>Testing the Fix</h4>

<p>
This bug was subtle enough that we wrote dedicated regression tests for
it (commit <code>8a59988</code>). Five handler-mode tests that verify
<code>g_inSyscall</code> behavior:
</p>

<p>
<strong>Test 1:</strong> Call <code>kernel::sleep()</code> from within a
simulated SVC dispatch (g_inSyscall=true). Assert that it actually
blocks the thread instead of returning immediately.
</p>

<p>
<strong>Test 2:</strong> Call <code>kernel::sleep()</code> from a real
ISR context (g_inSyscall=false, simulated VECTACTIVE nonzero). Assert
that it correctly refuses to block.
</p>

<p>
<strong>Test 3:</strong> Call <code>kernel::mutexLock()</code> from SVC
dispatch. Assert that it blocks when the mutex is held.
</p>

<p>
<strong>Test 4:</strong> Call <code>kernel::semaphoreWait()</code> from
SVC dispatch. Assert that it blocks when the count is zero.
</p>

<p>
<strong>Test 5:</strong> Call <code>kernel::messageSend()</code> from SVC
dispatch. Assert that it blocks when the target mailbox is full.
</p>

<p>
The regression proof is simple: remove the <code>g_inSyscall</code>
check from <code>inIsrContext()</code>, and three of these five tests
fail instantly. The flag is load-bearing. The tests guarantee it stays.
</p>

<p>
For the complete SVC dispatch flow diagram, see the
<a href="architecture.html#syscall">Architecture Guide</a>. For the
exact GDB commands used to trace ISR-context bugs, see the
<a href="debugging-playbook.html#isr-early-return">Debugging Playbook</a>.
</p>

<h3>The MPU Wall</h3>

<p>
With the SVC silent-failure bug fixed, the unprivileged echo client
should have been working. And it was&mdash;for about two hundred
milliseconds. Then the board rebooted. Fast LED blink: the crash-reboot
loop we knew all too well from Phase 4.
</p>

<h4>The Crash Dump</h4>

<p>
The crash dump system from Phase 1 earned its keep. We connected the
serial terminal and caught the output before the reboot:
</p>

<pre>
=== CRASH DUMP BEGIN ===
Fault: MemManage
Thread: echo-cli (id=2)
MMFSR: 0x82
Decoded:
  -> DACCVIOL: Data access violation
  -> MMARVALID: MMFAR = 0x20000104
=== CRASH DUMP END ===
</pre>

<p>
A data access violation. The faulting address: <code>0x20000104</code>.
That address is in SRAM, in the <code>.bss</code> section. The MemManage
fault fired because an unprivileged thread tried to read from a memory
region that the MPU marks as privileged-only.
</p>

<h4>The Offending Code</h4>

<p>
We looked at the echo client's source code:
</p>

<pre>
<span class="kw">static</span> kernel::ThreadId g_serverTid;  <span class="cmt">// .bss at 0x20000104</span>

<span class="kw">void</span> <span class="fn">echoClientMain</span>(<span class="kw">void</span> *arg)
{
    kernel::ThreadId server = g_serverTid;  <span class="cmt">// BOOM -- MPU fault</span>
    <span class="cmt">// ...</span>
}
</pre>

<p>
A global variable. Sitting innocently in <code>.bss</code>. In MPU
Region 1, which covers all of SRAM as "Privileged RW, Unprivileged No
Access." We had configured this in Phase 3 to protect kernel data
structures from rogue threads. And now the protection was working
exactly as designed&mdash;against our own echo client.
</p>

<p>
The unprivileged thread could access its own stack (MPU Region 4,
per-thread, configured during context switch) and the heap (MPU Region
5, user RW). But it could not access <em>anything</em> in the general
SRAM region: no globals, no static variables, no kernel data. The MPU
does not care that <code>g_serverTid</code> is a simple integer that
the client wrote before spawning the thread. It is in the forbidden
zone. Access denied.
</p>

<h4>The Fix</h4>

<p>
The solution was to pass the server's thread ID through the thread
argument pointer. The <code>createThread()</code> function accepts a
<code>void *arg</code> that gets placed in the new thread's initial r0.
It lives on the creating thread's stack at the moment of creation, then
gets copied into the initial stack frame of the new thread&mdash;which
is in the new thread's own MPU-accessible stack region.
</p>

<pre>
<span class="cmt">// Application code -- pass server TID via thread argument</span>
kernel::ThreadId serverTid = kernel::createThread(<span class="str">"echo-srv"</span>, ...);

<span class="cmt">// Cast to void* for the thread arg (fits in 32 bits)</span>
<span class="kw">void</span> *arg = <span class="kw">reinterpret_cast</span><<span class="kw">void</span> *>(serverTid);
kernel::createThread(<span class="str">"echo-cli"</span>, echoClientMain, arg, <span class="num">512</span>, <span class="num">15</span>, <span class="kw">false</span>);

<span class="kw">void</span> <span class="fn">echoClientMain</span>(<span class="kw">void</span> *arg)
{
    <span class="kw">auto</span> server = <span class="kw">reinterpret_cast</span>&lt;kernel::ThreadId&gt;(arg);  <span class="cmt">// from r0, safe</span>
    <span class="cmt">// ...</span>
}
</pre>

<p>
No global. No static. The data flows through the thread creation
mechanism itself, landing in a register that the thread can read from
its own privilege domain.
</p>

<div class="lesson">
<strong>Lesson:</strong> Unprivileged threads live in a small world:
their stack and the heap. Everything else&mdash;globals, statics,
peripherals, kernel data structures&mdash;is behind the MPU wall.
Design your data flow accordingly. If an unprivileged thread needs a
value, pass it through the thread argument, through a message, or
through a heap-allocated buffer. Do not assume that a pointer to a
global is valid from every execution context.
</div>

<h3>Testing the Boundary</h3>

<p>
With both bugs fixed&mdash;the silent SVC failure and the MPU
global-access fault&mdash;the unprivileged echo client ran correctly.
It sent messages via SVC, received replies via SVC, and slept via SVC.
It could not access peripherals directly (no UART, no GPIO, no RCC). It
could not disable interrupts. It could not corrupt kernel state. It was
a well-behaved citizen of a well-guarded microkernel.
</p>

<p>
The test suite grew to cover the new privilege boundary. The SVC dispatch
tests (23 tests for each syscall number) verify that every kernel
function is reachable through the trap interface. The handler-mode tests
(5 tests) verify the <code>g_inSyscall</code> flag. The existing IPC
tests still pass because privileged threads continue to call kernel
functions directly&mdash;no SVC overhead, no behavior change.
</p>

<p>
The total kernel overhead for the privilege system is remarkably small:
</p>

<div class="diagram">
  <span class="label">Phase 6 Kernel Overhead</span>

  Component               Size
  ---------               ----
  TCB extension            32 bytes  (1 bool + padding, per thread)
  SVC_Handler asm          80 bytes  (number extraction + dispatch call)
  PendSV CONTROL update    20 bytes  (load, compare, write, ISB)
  svcDispatch() C++       500 bytes  (switch table, 23 cases)
  g_inSyscall flag          4 bytes  (1 volatile bool + alignment)
  ---------               ----
  Total:                  ~650 bytes
</div>

<p>
Six hundred and fifty bytes. That is the cost of a complete hardware-
enforced privilege boundary with 24 system calls, dual-mode operation,
and ISR-context disambiguation. On a chip with a megabyte of flash, it
is invisible. On a chip with 64 KB, it would still be worth every byte.
</p>

<div class="highlight">
<strong>Status after Phase 6:</strong> ms-os enforces a hardware privilege
boundary. Unprivileged threads use SVC for all kernel services. The MPU
prevents unauthorized access to kernel memory, peripherals, and other
threads' stacks. 24 system calls cover the full kernel API. The
<code>g_inSyscall</code> flag distinguishes SVC dispatch from true ISR
context, enabling blocking syscalls to work correctly from Handler mode.
297 host tests passing, all existing tests unmodified.
</div>

<!-- ============================================================ -->
<!--                     CHAPTER 8                                -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 8</span>
  Describing the Hardware (Phase 7)
</h2>

<div class="epigraph">
  "All problems in computer science can be solved by another level of
  indirection."
  <div class="attribution">&mdash; David Wheeler</div>
</div>

<p>
Three boards. Three sets of hardcoded clock frequencies, pin assignments,
and memory addresses scattered across startup code, HAL implementations,
and application logic. Every time we added a target, we played
whack-a-mole with magic numbers. The F207 runs at 120 MHz with APB1 at
30 MHz. The F407 runs at 168 MHz with APB1 at 42 MHz. The PYNQ-Z2 runs
at 650 MHz with a 100 MHz UART reference clock. These numbers appeared
in SystemInit, in UART baud rate calculations, in SysTick configuration,
in the shell's uptime display. Change one, grep for the others, hope you
caught them all.
</p>

<p>
It was time to describe the hardware once and let the build system figure
out the rest.
</p>

<h3>The First Attempt: YAML</h3>

<p>
Our first approach was pragmatic: write a YAML file for each board,
build a Python code generator (<code>dtgen</code>) to parse it, and emit
C++ constexpr headers. One YAML file per board, one generated header,
one source of truth.
</p>

<p>
It worked. We wrote 67 Python tests for dtgen, covering schema
validation, error handling, and output correctness. The generated headers
were clean, the build integration was smooth, and applications could use
<code>if constexpr (board::kHasLed)</code> for compile-time optional
features. For a single-project solution, it was perfectly adequate.
</p>

<p>
But it was proprietary. Nobody else in the world used ms-os YAML board
files. There was no ecosystem, no tooling support, no community
documentation. We were maintaining a custom schema, a custom parser, and
a custom code generator for something that the embedded industry had
already solved decades ago. Every time we changed the schema, every
board file and every test needed updating. The maintenance burden was
small but constant, and it would only grow.
</p>

<h3>The Standard</h3>

<p>
The Flattened Device Tree (FDT) format. Linux uses it. Zephyr uses it.
U-Boot uses it. FreeBSD uses it. The <code>dtc</code> (device tree
compiler) is a standard tool available on every Linux distribution.
The DTS (Device Tree Source) format is human-readable. The DTB (Device
Tree Blob) binary is compact and parseable with zero allocations.
</p>

<p>
"Why invent a format when one already exists?"
</p>

<p>
The rework replaced YAML entirely. Each board gets a <code>.dts</code>
file written in the standard DTS v1 syntax:
</p>

<pre>
<span class="cmt">// boards/stm32f207zgt6.dts</span>
/dts-v1/;
/ {
    compatible = <span class="str">"ms-os,stm32f207zgt6"</span>;
    model = <span class="str">"STM32F207ZGT6"</span>;
    board { name = <span class="str">"Custom (F207)"</span>; mcu = <span class="str">"STM32F207ZGT6"</span>; };
    clocks { system-clock = <<span class="num">120000000</span>>; };
    memory { flash { reg = <<span class="num">0x08000000 0x100000</span>>; }; };
    console { uart = <<span class="num">2</span>>; baud = <<span class="num">115200</span>>; };
};
</pre>

<p>
A Python toolchain converts DTS to binary and embeds it in firmware:
<code>fdtlib.py</code> builds the FDT binary from Python objects,
<code>build_dtbs.py</code> orchestrates the pipeline for all boards,
and <code>dtb2cpp.py</code> embeds the resulting binary as a C++
<code>const uint8_t[]</code> array linked into the firmware image. At
boot, the kernel parses the embedded DTB blob and fills a
<code>BoardConfig</code> struct. No runtime file I/O. No filesystem
dependency. The device tree is part of the binary.
</p>

<h3>Building the Parser</h3>

<p>
The FDT binary format is elegantly simple. It starts with a header
containing a magic number and structure offsets, followed by a token
stream describing the tree, and a strings block at the end containing
property names.
</p>

<div class="highlight">
<strong>FDT Magic Number:</strong> <code>0xD00DFEED</code>. If the first
four bytes of a blob are not 0xD00DFEED (big-endian), it is not a valid
device tree. This is the first check the parser makes, and it catches
corruption, wrong files, and byte-order mistakes immediately.
</div>

<p>
The token stream consists of four token types:
</p>

<div class="diagram">
  <span class="label">FDT Token Stream</span>

  Token           Value        Meaning
  -----           -----        -------
  FDT_BEGIN_NODE  0x00000001   Start of a node (followed by name)
  FDT_END_NODE    0x00000002   End of a node
  FDT_PROP        0x00000003   Property (followed by length + name offset)
  FDT_END         0x00000009   End of the structure block

  Walking the tree:

  BEGIN_NODE "/"
    PROP "compatible" = "ms-os,stm32f207zgt6"
    BEGIN_NODE "board"
      PROP "name" = "Custom (F207)"
      PROP "mcu" = "STM32F207ZGT6"
    END_NODE
    BEGIN_NODE "clocks"
      PROP "system-clock" = &lt;120000000&gt;
    END_NODE
  END_NODE
  END
</div>

<p>
Our parser (<code>Fdt.h</code> / <code>Fdt.cpp</code>) walks this
stream in ~300 lines of C++. It provides <code>findNode()</code> to walk
a path like <code>/clocks</code>, <code>findProperty()</code> to locate
a named property within a node, and <code>readU32()</code> /
<code>readString()</code> to extract typed values. All multi-byte values
in DTB are big-endian; the parser converts with
<code>__builtin_bswap32()</code>. All pointers returned by the parser
point directly into the DTB blob&mdash;no copies, no allocations. The
parser is inherently thread-safe because it never modifies the blob.
</p>

<h3>The dt Command</h3>

<p>
The shell gained a <code>dt</code> command that displays the parsed
device tree at runtime. Type <code>dt</code> and see the board's
identity, clock tree, memory map, console configuration, and LED pin
assignment. All from the embedded DTB, parsed at boot, formatted for
human consumption. Developers can verify the board configuration on
live hardware without reading source code or build logs.
</p>

<h3>Three Boards, One Format</h3>

<p>
Three DTS files now describe the complete hardware configuration for all
three targets: board identity (compatible string, model name), clock
tree (SYSCLK, APB1, APB2, HSE or UART reference clock), memory regions
(flash base and size, SRAM, optional CCM), console UART (peripheral
number, baud rate, TX/RX pin assignments with alternate function
numbers), LED pin, and feature flags (FPU presence, architecture
family). The build system selects the right DTS file based on
<code>MSOS_TARGET</code>, compiles it to DTB, embeds it as a C++ array,
and links it into the firmware. Adding a new board means writing one DTS
file and adding one line to the CMake target list.
</p>

<p>
The dtgen YAML tool was not deleted&mdash;its 67 tests still run in CI
as a regression safety net for the Python infrastructure. But the
firmware no longer uses it. The device tree is standard FDT, parseable
by any tool in the ecosystem.
</p>

<div class="highlight">
<strong>Status after Phase 7:</strong> Board configuration lives in standard
FDT device trees. Three DTS source files, a Python build pipeline
(fdtlib + build_dtbs + dtb2cpp, 21 new Python tests), and a kernel FDT
parser replace all hardcoded board constants. The shell <code>dt</code>
command displays the parsed tree at runtime. 67 dtgen tests + 21 dtb2cpp
tests = 88 total Python tests for the device tree toolchain.
</div>

<p>
See the <a href="architecture.html#device-tree">Architecture Guide</a>
for FDT format details and the complete DTS schema.
</p>

<!-- ============================================================ -->
<!--                     CHAPTER 9                                -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 9</span>
  Conserving Every Milliamp (Phase 8)
</h2>

<div class="epigraph">
  "Perfection is achieved not when there is nothing more to add, but
  when there is nothing left to take away."
  <div class="attribution">&mdash; Antoine de Saint-Exupery</div>
</div>

<h3>The Spinning Idle Thread</h3>

<p>
The idle thread used to spin. An infinite loop doing nothing, burning
every cycle the CPU had to offer, generating heat for no purpose.
</p>

<pre>
<span class="cmt">// The old idle thread -- a monument to waste</span>
<span class="kw">void</span> <span class="fn">idleMain</span>(<span class="kw">void</span> *)
{
    <span class="kw">while</span> (<span class="kw">true</span>)
    {
        <span class="cmt">// do nothing, but do it at 120 MHz</span>
    }
}
</pre>

<p>
On a wall-powered development board, nobody notices. The F207 draws
maybe 80 mA whether the idle thread spins or not&mdash;the difference is
lost in the noise of the power LED and the JTAG interface. But on a
battery-powered sensor node, that idle loop is the difference between
lasting a week and lasting a day. An idle CPU burning 50 mA continuously
drains a 500 mAh coin cell in ten hours. The same CPU sleeping at 2 mA
stretches that to ten days.
</p>

<p>
Phase 8 was about teaching the kernel to rest.
</p>

<h3>The Instruction That Changes Everything</h3>

<p>
WFI. Wait For Interrupt. Three letters, one instruction, and the single
most power-efficient line of code in the entire kernel.
</p>

<pre>
<span class="cmt">// The new idle thread</span>
<span class="kw">void</span> <span class="fn">idleMain</span>(<span class="kw">void</span> *)
{
    <span class="kw">while</span> (<span class="kw">true</span>)
    {
        arch::waitForInterrupt();  <span class="cmt">// WFI -- CPU sleeps until next IRQ</span>
    }
}
</pre>

<p>
When the CPU executes WFI, it halts its pipeline, stops its internal
clocks, and enters a low-power state. Current drops from tens of
milliamps to microamps. The chip is not off&mdash;SRAM retains its
contents, the NVIC watches for interrupts, the SysTick timer keeps
counting. But the core itself is dormant. When the next interrupt
fires&mdash;SysTick, a peripheral IRQ, an external event&mdash;the CPU
wakes in nanoseconds, handles the interrupt, runs the scheduler, and
either dispatches a ready thread or drops back into the idle loop and
sleeps again.
</p>

<p>
The most power-efficient code is the code that does not run.
</p>

<h3>The Levels of Sleep</h3>

<p>
ARM provides a spectrum of low-power states, and we exposed three of
them through the architecture abstraction layer:
</p>

<p>
<strong>Level 1: WFI (light sleep).</strong> The core sleeps, peripherals
keep running, wake on any interrupt. Latency: nanoseconds. This is the
default idle behavior, suitable for any workload. The idle thread calls
<code>arch::waitForInterrupt()</code> in its main loop.
</p>

<p>
<strong>Level 2: SLEEPONEXIT.</strong> When this bit is set in the
Cortex-M System Control Register (SCR), the CPU automatically enters WFI
when returning from any ISR to Thread mode, instead of resuming the idle
thread just to execute WFI again. This eliminates one unnecessary context
switch per interrupt&mdash;the CPU goes directly from "handle interrupt"
to "sleep" without waking the idle thread in between.
</p>

<p>
<strong>Level 3: SLEEPDEEP.</strong> Setting the SLEEPDEEP bit changes
WFI from light sleep to Stop mode. The PLLs shut down. The oscillators
stop. The flash enters standby. Power consumption drops by an order of
magnitude, but wake latency increases&mdash;the PLLs need to relock,
the flash needs to stabilize. This mode is opt-in for applications
that can tolerate longer interrupt response times.
</p>

<p>
The Cortex-A9 on the PYNQ-Z2 gets WFI but not SLEEPONEXIT or SLEEPDEEP.
The Zynq's power management is handled by the Processing System (PS)
power controller, which lives in the FPGA fabric and requires an entirely
different programming model. The architecture abstraction layer provides
the functions on A9 but they are no-ops&mdash;the WFI instruction still
works, and that alone is a significant improvement over spinning.
</p>

<h3>Clock Gating</h3>

<p>
Beyond sleeping the CPU, we added functions to disable peripheral clocks
when they are not in use: <code>rccDisableGpioClock()</code> and
<code>rccDisableUartClock()</code>. Every peripheral on an STM32 draws
current from its bus clock even when idle. Turning off the clock to a
GPIO port you are not using saves a few hundred microamps. It adds up.
</p>

<p>
The API mirrors the existing <code>rccEnableGpioClock()</code> functions
from Phase 0. Symmetric enable/disable, same port/peripheral identifiers,
same register-level implementation. The application decides when to gate
clocks based on its usage pattern. The kernel does not make assumptions
about which peripherals are needed.
</p>

<h3>Testing the Untestable</h3>

<p>
You cannot test WFI on x86. There is no equivalent instruction, no way
to measure current draw, no way to verify that the CPU actually entered
a low-power state. The mock architecture layer does the only thing it
can: track state in global variables.
</p>

<pre>
<span class="cmt">// MockArch.cpp -- power management mocks</span>
<span class="kw">uint32_t</span> g_wfiCount = <span class="num">0</span>;
<span class="kw">bool</span> g_deepSleep = <span class="kw">false</span>;
<span class="kw">bool</span> g_sleepOnExit = <span class="kw">false</span>;

<span class="kw">void</span> <span class="fn">waitForInterrupt</span>() { g_wfiCount++; }
<span class="kw">void</span> <span class="fn">enableDeepSleep</span>() { g_deepSleep = <span class="kw">true</span>; }
<span class="kw">void</span> <span class="fn">enableSleepOnExit</span>() { g_sleepOnExit = <span class="kw">true</span>; }
</pre>

<p>
Ten new tests assert the flags: "after calling
<code>waitForInterrupt()</code> three times, <code>g_wfiCount</code>
should be 3." "After calling <code>enableDeepSleep()</code>, the flag
should be true." Functional correctness, not electrical measurement. We
trust the hardware manual for the rest&mdash;ARM's architects have
verified that WFI actually reduces power consumption. Our job is to
verify that the kernel calls WFI at the right times.
</p>

<div class="highlight">
<strong>Status after Phase 8:</strong> The idle thread sleeps via WFI
instead of busy-looping. Sleep-on-exit eliminates unnecessary context
switches between interrupts. Deep sleep is available for power-sensitive
applications. Clock gating functions disable unused peripherals.
Three-function power API, zero heap allocations, 10 new tests, fully
testable on host.
</div>

<!-- ============================================================ -->
<!--                     CHAPTER 10                               -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 10</span>
  A Window Into the Kernel (Phase 9)
</h2>

<div class="epigraph">
  "The purpose of computing is insight, not numbers."
  <div class="attribution">&mdash; Richard Hamming</div>
</div>

<p>
Until this moment, the only way to know what ms-os was thinking was to
read crash dumps or litter the code with printf statements. The kernel
was a black box with a serial port. We could flash firmware, watch LEDs
blink, and catch fault output when things went wrong. But we had no way
to ask the running kernel "what are you doing right now?" No way to peek
at thread states without attaching a debugger. No way to check heap
usage without adding temporary instrumentation and reflashing.
</p>

<p>
Phase 9 gave the kernel a voice&mdash;and more importantly, it gave us
ears.
</p>

<h3>The First Keypress</h3>

<p>
Connect a terminal to <code>/dev/ttyUSB0</code>, 115200 baud, 8N1.
The shell thread starts at priority 20, polling
<code>uartTryGetChar()</code> every 10 milliseconds. It is the
lowest-priority interactive task in the system&mdash;below the echo
server, below the LED blinker, above only the idle thread.
</p>

<p>
Type 'h'. The character echoes on screen. Type 'e'. Echo. Type 'l', 'p',
Enter.
</p>

<pre>
ms-os> help
Available commands:
  help     - Show this help
  ps       - List threads
  mem      - Show heap statistics
  uptime   - Show system uptime
  version  - Show ms-os version
  dt       - Show device tree
ms-os>
</pre>

<p>
We were talking to the kernel. Not through a debugger, not through a
crash dump, not through a compile-time printf that required reflashing.
A live conversation, character by character, with a running RTOS.
</p>

<h3>The ps Revelation</h3>

<p>
The <code>ps</code> command was the moment the kernel became transparent.
Type three characters and Enter:
</p>

<pre>
ms-os> ps
TID  NAME         STATE    PRI  STACK
  0  idle         Ready      31   256
  1  echo-srv     Blocked    10  1024
  2  echo-cli     Blocked    15   512
  3  led          Sleeping    5   512
  4  shell        Running    20   512
ms-os>
</pre>

<p>
For the first time, we could see the kernel's world from outside. Five
threads. The echo server blocked, waiting for a message that would never
come unless the client woke up. The echo client blocked, waiting for the
reply to its last request. The LED thread sleeping between blinks&mdash;it
called <code>sleep(500)</code> and would not wake for another 340
milliseconds. The shell itself, running, processing our keystrokes, the
only thread that needed the CPU right now.
</p>

<p>
It was like X-ray vision for the kernel. We could watch scheduling
decisions play out in real time. Send a burst of echo requests, and
the client and server would flip between Blocked and Ready. Kill the
LED blink interval by shortening the sleep, and the LED thread would
appear as Running more often. Everything the scheduler was doing
internally was now visible externally, one <code>ps</code> command at
a time.
</p>

<h3>mem and uptime</h3>

<p>
<code>mem</code> provides a snapshot of heap health:
</p>

<pre>
ms-os> mem
Heap: 1024/16384 bytes used (6%)
Free: 15360 bytes
Peak: 1024 bytes
Allocs: 4
Largest free: 15360 bytes
ms-os>
</pre>

<p>
The "Largest free" metric is deceptively important. Total free bytes
tells you how much memory is available in aggregate. Largest free block
tells you the biggest single allocation that can succeed. If total free
is 10 KB but the largest free block is 256 bytes, your heap is
fragmented and a 1 KB allocation will fail even though "there is plenty
of memory." This single number reveals fragmentation without needing
a full heap walk command.
</p>

<p>
<code>uptime</code> gives the simplest possible health indicator:
</p>

<pre>
ms-os> uptime
Uptime: 127 seconds (127000 ticks)
ms-os>
</pre>

<p>
If uptime keeps increasing, the system is alive. If it resets to zero,
the board rebooted. Combined with the crash dump system, you can tell
not just <em>that</em> a crash happened but <em>when</em>&mdash;the
uptime before the crash dump tells you how long the system survived.
</p>

<p>
<code>version</code> shows the ms-os version string.
<code>dt</code> displays the parsed device tree: board name, MCU,
architecture, clock frequencies, memory regions with base addresses
and sizes, console UART configuration, and LED pin. Six commands, each
one a window into a different aspect of the running system.
</p>

<h3>Character-Driven Design</h3>

<p>
The shell's architecture was a deliberate choice to avoid complexity.
There is no UART receive interrupt handler. There is no DMA channel for
input. There is no ring buffer of received characters managed by the
kernel. The shell is <strong>passive</strong>: the application thread
polls the UART with <code>uartTryGetChar()</code> and feeds each byte to
<code>shellProcessChar()</code>. One character at a time.
</p>

<p>
Why? Three reasons.
</p>

<p>
First, <strong>testability</strong>. The shell output goes through a
function pointer (<code>ShellWriteFn</code>), not a direct UART call.
In tests, we provide a callback that appends to a
<code>std::string</code>. We feed characters to
<code>shellProcessChar()</code> and assert on the captured output string.
No hardware, no mocks of serial peripherals, no simulated register
state. Just strings in, strings out. It is the simplest possible test
harness.
</p>

<p>
Second, <strong>portability</strong>. The shell does not know or care
what kind of UART it is connected to. It could be an STM32 USART with
polled I/O, a Zynq PS UART with FIFO mode, a virtual UART over
semihosting, or a TCP socket in a simulator. The function pointer
abstraction means the shell works with any output backend that can write
a string.
</p>

<p>
Third, <strong>simplicity</strong>. A receive interrupt handler needs an
ISR, a ring buffer, synchronization between the ISR and the consumer
thread, and careful handling of buffer overflow. For a debug shell that
processes human typing speeds (maybe 10 characters per second), that
machinery is overkill. Polling at 10 ms intervals with
<code>uartTryGetChar()</code> is more than fast enough and costs zero
interrupt overhead.
</p>

<p>
Line editing is minimal but functional: printable characters are echoed
and appended to an 80-byte buffer. Backspace and DEL erase the last
character. Enter dispatches the command. There is no cursor movement, no
command history, no tab completion. Those are luxuries for a future
phase. For now, the shell does exactly what a kernel debug console needs
to do: accept commands and show results.
</p>

<h3>No sprintf, No Problem</h3>

<p>
The freestanding environment presented one last challenge: number
formatting. The <code>ps</code> command needs to print thread IDs,
priorities, and stack sizes as decimal numbers. The <code>mem</code>
command prints byte counts and percentages. The <code>uptime</code>
command prints seconds. But there is no <code>sprintf</code> in a
freestanding kernel&mdash;pulling in the C standard library's formatter
would add 50 KB or more to the binary.
</p>

<p>
So we wrote our own. <code>uintToStr()</code> converts a
<code>uint32_t</code> to a decimal string by repeatedly dividing by 10
and collecting digits in reverse. <code>hexToStr()</code> does the same
with shifts and masks. Column alignment for the <code>ps</code> table
uses fixed-width string padding&mdash;right-align the TID in a 3-
character field, left-align the name in a 12-character field.
</p>

<p>
It is not pretty code. The digit-reversal loop, the manual padding,
the character-by-character output&mdash;it reads like something from a
1980s systems programming textbook. But it works without pulling in any
external dependencies, it fits in a few hundred bytes, and it produces
correctly formatted output that 24 tests verify exhaustively.
</p>

<div class="highlight">
<strong>Status after Phase 9:</strong> ms-os has an interactive shell with
six commands for runtime introspection: <code>help</code>,
<code>ps</code>, <code>mem</code>, <code>uptime</code>,
<code>version</code>, and <code>dt</code>. Character-driven design with
function-pointer output for testability. Custom integer and hex formatters
for the freestanding environment. 24 new ShellTest tests. Connect a
terminal at 115200 baud and type <code>ps</code> to see your threads.
</div>

<p>
For how to use the shell during hardware debugging sessions, see the
<a href="debugging-playbook.html#serial">Debugging Playbook</a>.
</p>

<!-- ============================================================ -->
<!--                     CHAPTER 11                               -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 11</span>
  The Safety Net (CI &amp; GitHub Pages)
</h2>

<div class="epigraph">
  "Move fast and break things. Then add CI so you catch the breaks."
  <div class="attribution">&mdash; Adapted</div>
</div>

<p>
By this point ms-os had 297 C++ unit tests, 135 Python tests, three
cross-compilation targets, and ten completed phases of development. All
of it built and tested manually. Every merge was a <code>python3
build.py -t</code> on one developer's machine with one compiler. The
CLAUDE.md file had aspirationally mentioned "GitHub Actions with matrix
testing (GCC + Clang, Debug + Release)" since Phase 0, but no workflow
existed. Ten phases later, we finally built it.
</p>

<p>
A bare-metal RTOS has a unique CI challenge: you cannot run the firmware
in CI. There is no hardware in a GitHub Actions runner. You cannot flash
a board, watch an LED, or read serial output. But you <em>can</em>
verify everything that does not require silicon: host-compiled unit
tests, Python code generator tests, and cross-compilation itself. If
the ARM build fails in CI, you know immediately&mdash;not after flashing
a board and wondering why the LED does not blink.
</p>

<h3>The Matrix</h3>

<p>
The CI workflow (<code>.github/workflows/ci.yml</code>) defines three
jobs that run in parallel, totaling eight parallel execution cells:
</p>

<div class="diagram">
  <span class="label">CI Matrix: 8 Parallel Jobs</span>

  Host Tests (2x2 matrix):
  +----------+----------+
  |          | Debug    | Release  |
  +----------+----------+----------+
  | GCC      |  cell 1  |  cell 2  |
  | Clang    |  cell 3  |  cell 4  |
  +----------+----------+----------+

  Python Tests:
  +------------------------------+
  | dtgen + ipcgen + dtb2cpp     |  cell 5
  +------------------------------+

  Cross-Compilation (3 targets):
  +----------+----------+----------+
  | F207     | F407     | PYNQ-Z2  |
  | cell 6   | cell 7   | cell 8   |
  +----------+----------+----------+

  fail-fast: false
  <span class="comment">-- We want to see ALL the breakage, not just the first failure.</span>
</div>

<p>
Each host test cell checks out the repository with submodules (Google
Test lives in <code>test/vendor/googletest</code>), configures CMake with
the appropriate compiler and build type, builds the test executables, and
runs <code>ctest --output-on-failure</code>. The
<code>fail-fast: false</code> setting is critical: if the GCC Debug cell
fails, we still want to see whether Clang Release also fails, and
whether it fails for the same reason or a different one.
</p>

<p>
Python tests run pytest across three test directories: the dtgen schema
tests (67 tests), the ipcgen embedded emitter tests (40 tests), and the
dtb2cpp round-trip tests (21 tests). These verify the code generation
toolchain that produces C++ source from IDL files and device tree
descriptions.
</p>

<p>
Cross-compilation runs a 3-element matrix over the hardware targets:
stm32f207zgt6, stm32f407zgt6, and pynq-z2. Each cell installs the ARM
toolchain from Ubuntu's package repository, configures CMake with the
cross-compilation toolchain file and the target variable, and builds the
firmware. No flashing, no testing&mdash;just "does it compile?" This
catches linker script errors, missing symbols, and architecture-specific
build failures.
</p>

<h3>The Clang Surprise</h3>

<p>
The very first CI run revealed why running two compilers matters. GCC
13.2.0 had been our only compiler for ten phases. Every warning flag was
tuned to GCC. Every template edge case happened to work the way GCC
expected. Clang had opinions.
</p>

<p>
The first failure was the <code>g_inSyscall</code> declaration from
Phase 6:
</p>

<pre>
<span class="cmt">// Arch.cpp -- GCC accepted this silently</span>
<span class="kw">extern</span> <span class="str">"C"</span> <span class="kw">volatile</span> <span class="kw">bool</span> g_inSyscall = <span class="kw">false</span>;
</pre>

<p>
GCC compiled it without a whisper. Clang raised a warning: "variable
'g_inSyscall' is both 'extern' and initialized." With
<code>-Werror</code> enabled, that warning became a hard error. The fix
was to drop the <code>extern</code> on the definition (keeping it only
on the declaration in the header). Technically GCC was being too lenient&mdash;the
C++ standard says a declaration with an initializer is a definition, and
<code>extern</code> on a definition is at best redundant and at worst
misleading.
</p>

<p>
Clang also flagged different template instantiation order issues and
stricter type conversion warnings. Each one was a legitimate code
quality issue that GCC's warning heuristics happened to overlook.
</p>

<div class="lesson">
<strong>Lesson:</strong> Running two compilers is like having two code
reviewers with different personalities. GCC is your experienced colleague
who lets minor style issues slide because the code works. Clang is the
new hire who reads the standard literally and flags everything. You need
both.
</div>

<h3>The Cross-Compilation Firewall</h3>

<p>
The three cross-compilation targets cannot run in CI&mdash;there is no
F207, no F407, no PYNQ-Z2 plugged into a GitHub Actions runner. But
compilation alone catches a surprising number of bugs:
</p>

<p>
Missing <code>#include</code> directives that only one target needs (the
PYNQ-Z2 startup requires different headers than STM32). Linker errors
from symbols that exist in the Cortex-M HAL but not the A9 HAL.
Architecture-specific compile flags that break when applied to the wrong
target. Conditional compilation paths that are syntactically valid but
semantically wrong on a different CPU.
</p>

<p>
The CI cannot tell you if the LED blinks. But it can tell you if the
binary that would blink the LED even compiles. On a project where
flashing and testing requires physical hardware, that early warning is
invaluable. A broken cross-compilation caught on push is a bug that
never makes it to the bench.
</p>

<h3>The pyserial Ambush</h3>

<p>
The most entertaining CI failure was meta: a bug in our test
infrastructure, caught by the test infrastructure.
</p>

<p>
The <code>crash_monitor.py</code> script (a serial-port tool for
capturing crash dumps from live hardware) imported <code>pyserial</code>
at the top of the file and called <code>sys.exit(1)</code> if the import
failed. Perfectly reasonable behavior for a command-line tool. But
<code>crash_monitor_test.py</code> imports <code>crash_monitor.py</code>
as a module for testing. When pytest collected the test file on a CI
runner without pyserial installed, the import triggered
<code>sys.exit(1)</code>, which raised <code>SystemExit</code>, which
pytest caught during test collection and reported as a collection error.
The entire Python test job exploded&mdash;not because a test failed,
but because a test file could not even be loaded.
</p>

<p>
The fix had two parts: defer the <code>sys.exit()</code> call to the
<code>if __name__ == "__main__"</code> guard (so importing the module
does not exit the process), and exclude hardware-dependent tests from
the CI test suite. The CI was working as designed&mdash;it found a bug.
Just not the kind of bug we expected.
</p>

<h3>The README Refresh</h3>

<p>
While setting up CI, we discovered that the README had fallen behind.
Phase 6 was missing from the features table. The test count still said
269 (it was 297). The Python test count said 135 (now 152 with the
dtb2cpp additions). The story link pointed to a raw HTML file on GitHub,
which GitHub renders as source code rather than a web page.
</p>

<p>
All fixed in the same commit. A CI badge at the top of the README now
shows build status at a glance&mdash;the project's heartbeat, green or
red, updated on every push.
</p>

<h3>GitHub Pages</h3>

<p>
The project story&mdash;this very document&mdash;deserved better than
being rendered as raw HTML source. A second workflow
(<code>.github/workflows/pages.yml</code>) deploys the
<code>docs/</code> directory to GitHub Pages whenever it changes. The
workflow uses the modern <code>actions/deploy-pages</code> action with
OIDC token authentication&mdash;no personal access tokens, no deploy
keys. A concurrency group ensures only one deployment runs at a time,
and <code>cancel-in-progress</code> kills stale deployments when a new
push arrives.
</p>

<div class="key-decision">
<strong>Post-push manual step:</strong> The repository owner must visit
GitHub Settings > Pages and set Source to "GitHub Actions" (one-time).
After that, the Pages workflow deploys automatically on every docs change.
</div>

<div class="highlight">
<strong>Status after CI setup:</strong> Every push to main triggers 8
parallel CI jobs: 4 host-test matrix cells (GCC/Clang x Debug/Release),
1 Python test job, and 3 cross-compilation targets. 297 C++ tests, 135
Python tests, 3 cross-compile targets, 2 compilers. The project story is
served as a rendered web page via GitHub Pages. The README reflects
current test counts and features.
</div>

<!-- ============================================================ -->
<!--                     CHAPTER 12                               -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 12</span>
  The Night Shift
</h2>

<div class="epigraph">
  "Never go to sleep without a request to your subconscious."
  <div class="attribution">&mdash; Thomas Edison</div>
</div>

<p>
It was late. The kind of late where the terminal font starts to swim and
you realize you have been staring at a linker map for forty-five minutes
without blinking. The developer pushed back from the desk, stretched, and
typed four sentences that would change the trajectory of the project:
</p>

<p>
<em>"I want you to push commits to branches, merge branch to main and
push everything, don't wait for me."</em>
</p>

<p>
Then the screen went dark in the room. Somewhere in the apartment, a door
closed. And in the terminal, a cursor kept blinking.
</p>

<p>
What followed was a night of autonomous work&mdash;three features designed,
implemented, tested, cross-compiled, flashed, and merged. No review
cycles. No "LGTM" comments. No waiting. Just a machine and a codebase
and a list of things that needed doing.
</p>

<h3>The Quick Win: A Version String</h3>

<p>
Every serious OS can tell you what it is. Ask Linux its version and it
answers. Ask FreeRTOS and it answers. Ask ms-os before this night and it
would stare back silently&mdash;the <code>version</code> shell command
existed, but printed a hardcoded placeholder.
</p>

<p>
The fix was clean. A <code>kernel::version::kString</code> constant,
injected at compile time through a CMake macro that reads the version
number from a single source-of-truth variable. Change the version in
<code>CMakeLists.txt</code>, and every binary, every shell command, every
log message picks it up automatically. No manual synchronization, no
risk of the shell saying "0.9.0" while the bootloader thinks it is
"0.10.0."
</p>

<p>
Version bumped to <strong>0.10.0</strong>. First commit of the night.
Small, self-contained, satisfying. The kind of change that takes ten
minutes and pays dividends forever.
</p>

<h3>The Watchdog</h3>

<p>
A microcontroller without a watchdog is a microcontroller waiting to
hang. Cosmic rays flip bits. Interrupts fire in unexpected sequences.
Stack overflows corrupt return addresses. EMI from a nearby motor
injects noise on the bus. Any of these can send firmware into an
infinite loop, and without a watchdog, it stays there&mdash;forever.
The board locks up, the LED stops blinking, and nobody knows until
someone walks over and notices.
</p>

<p>
The STM32 Independent Watchdog (IWDG) is elegantly brutal. It has its
own dedicated 32 kHz RC oscillator, independent of the system clock.
If the main PLL locks up, the IWDG keeps counting. If the CPU hangs
in a busy loop, the IWDG keeps counting. If the flash controller
stalls, the IWDG keeps counting. And when its downcounter reaches zero,
it resets the entire chip. No negotiation. No graceful shutdown. A hard
reset, as if someone yanked the power and plugged it back in.
</p>

<p>
The protocol is a dance of magic numbers. Write <code>0x5555</code> to
the key register to unlock write access to the prescaler and reload
registers. Write your configuration. Write <code>0xAAAA</code> to reload
the counter. Write <code>0xCCCC</code> to start the watchdog. Once
started, it cannot be stopped&mdash;the IWDG has no off switch. This is
by design. If malicious or buggy code could disable the watchdog, the
entire safety mechanism would be pointless.
</p>

<div class="key-decision">
<strong>Key decision:</strong> The idle thread feeds the watchdog. This
is the simplest possible health indicator: if the scheduler can still
run the idle thread, the system is alive. If any higher-priority thread
enters an infinite loop, the idle thread starves, the watchdog times out,
and the MCU resets itself. No explicit health checks, no heartbeat
messages, no watchdog task&mdash;just the natural consequence of priority
scheduling.
</div>

<p>
The implementation required four files: the IWDG driver
(<code>hal::watchdog</code> namespace with <code>init</code>,
<code>feed</code>, and <code>isEnabled</code> functions), a mock for
host testing that records calls into global state, a shell command
(<code>wdt</code>) that prints the watchdog status and feed count, and
11 new tests verifying the initialization sequence, feeding behavior,
and error handling.
</p>

<p>
The Zynq-7000 on the PYNQ-Z2 has a system-level watchdog in the PS,
but configuring it requires accessing the System Level Control Registers
(SLCR) and navigating Xilinx's clock domain infrastructure. A stub was
provided&mdash;the functions exist, they compile, they do nothing. The
real Zynq watchdog driver can come later when there is hardware time
to validate it.
</p>

<h3>The Shell Learns a New Word</h3>

<p>
With the watchdog running, the shell needed a way to inspect it. Type
<code>wdt</code> and Enter:
</p>

<pre>
ms-os> wdt
Watchdog: enabled
Feeds: 847293
ms-os>
</pre>

<p>
That feed count is surprisingly useful. If the watchdog has been fed
847,293 times and the idle thread runs every millisecond, the system has
been alive for about 14 minutes without a single scheduling failure. If
you see the count stuck at some number, it means the idle thread stopped
running at that point&mdash;useful forensic data even after a watchdog
reset, if you capture serial output.
</p>

<h3>Dynamic Threads: The Recycling Problem</h3>

<p>
Until this night, thread IDs in ms-os were like social security numbers:
assigned once, never reused. Thread 0 was always the idle thread. Thread
1 was the first user thread. Thread 7 was the eighth. And when a thread
finished its work and was no longer needed? Its TCB slot sat there,
marked Inactive, wasting one of the precious eight slots in the thread
table. Create eight threads over the lifetime of the system, and you
could never create a ninth&mdash;even if seven of the eight had long
since completed.
</p>

<p>
For the blinky demo, this did not matter. For the IPC demo with its
fixed set of server, client, LED, and shell threads, this did not
matter. But for any real application&mdash;a network server that spawns
handler threads, a sensor system that creates measurement tasks on
demand, a shell that launches commands as separate threads&mdash;static
allocation is a death sentence. The system would eventually run out of
slots and refuse to create new threads, regardless of how many had
finished.
</p>

<p>
The solution was <code>threadDestroy()</code>: a function that takes a
thread ID and reclaims everything associated with it.
</p>

<h3>The Cleanup Chain</h3>

<p>
Destroying a thread is not simply zeroing a struct. A thread is woven
into the fabric of the kernel: it sits in the scheduler's ready queue
or a wait queue; it owns an IPC mailbox with potentially unread
messages; its TCB holds stack pointers, priority, privilege level, and
MPU configuration. All of it must be unwound in the correct order.
</p>

<p>
The cleanup chain runs in three stages. First, the scheduler removes
the thread from whatever queue it occupies&mdash;ready list, sleep list,
mutex wait queue, semaphore wait queue, or IPC block list. Second, the
IPC subsystem resets the thread's mailbox: clears any pending messages,
resets the ring buffer indices, clears the notification bitmask, unblocks
any threads that were waiting to send to this mailbox. Third, the TCB
itself is reset to its initial state&mdash;all fields zeroed, state set
to Inactive, ready for reuse.
</p>

<p>
Thread creation was updated to match: instead of always allocating the
next monotonically increasing slot, <code>createThread()</code> now
scans the TCB table for the first Inactive slot. If it finds one, it
reuses it. The thread gets a new name, a new priority, a new entry
point&mdash;but the same slot index as some previous thread that no
longer exists. Thread IDs are now recycled.
</p>

<h3>The kIdleThreadId Bug</h3>

<p>
The first test passed. The second test passed. The third test
crashed.
</p>

<p>
The test was straightforward: create a thread, destroy it, verify the
slot is Inactive. But <code>threadDestroy()</code> was rejecting the
request with an error code that meant "cannot destroy the idle thread."
The thread being destroyed was not the idle thread. It was a test
thread. But it had thread ID 0.
</p>

<p>
In the test environment, there is no idle thread. The first thread
created by a test gets slot 0. And <code>threadDestroy()</code> had a
guard:
</p>

<pre>
<span class="kw">if</span> (id == <span class="fn">kIdleThreadId</span>)  <span class="cmt">// kIdleThreadId = 0</span>
    <span class="kw">return</span> <span class="fn">kErrorInvalidId</span>;
</pre>

<p>
The constant <code>kIdleThreadId</code> was hardcoded to 0. The guard
assumed that slot 0 always belongs to the idle thread. In production,
that is true&mdash;the idle thread is always created first and always
gets slot 0. But in the test environment, there is no idle thread, and
slot 0 is just another slot.
</p>

<p>
The fix was to ask the scheduler which thread is actually the idle
thread, rather than assuming it is always slot 0:
</p>

<pre>
<span class="kw">if</span> (id == <span class="fn">scheduler</span>().<span class="fn">idleThreadId</span>())
    <span class="kw">return</span> <span class="fn">kErrorInvalidId</span>;
</pre>

<p>
In production, this returns 0. In tests where no idle thread exists, it
returns an invalid sentinel that never matches a real thread ID. The
guard still protects the idle thread, but it no longer makes assumptions
about which slot it occupies.
</p>

<div class="lesson">
<strong>Lesson:</strong> Hardcoded constants are assumptions in disguise.
<code>kIdleThreadId = 0</code> looked like a fact, but it was a
prediction about runtime state&mdash;a prediction that was true in
production and false in tests. When you find yourself writing
<code>if (x == MAGIC_NUMBER)</code>, ask: is this a compile-time truth
or a runtime assumption? If it is the latter, query the source of truth
instead.
</div>

<h3>Thirteen New Tests</h3>

<p>
Dynamic thread management is a minefield of edge cases, and every mine
got a test. Destroy a running thread? Error&mdash;you cannot pull the
rug from under a thread that is currently executing. Destroy the idle
thread? Error&mdash;the scheduler needs it. Destroy a thread that is
blocked on a mutex? The thread must be removed from the mutex's wait
queue before the slot is freed. Destroy a thread and then create a new
one? The new thread must get the recycled slot. Create the maximum
number of threads, destroy them all, create the maximum again? Every
slot must be reusable.
</p>

<p>
Thirteen tests, each one probing a different edge of the destroy/reuse
lifecycle. Combined with the 11 watchdog tests, the night added 24 new
test cases to the suite, bringing the total from 297 to 321.
</p>

<h3>The Three-Target Gauntlet</h3>

<p>
Every change that touches the kernel must compile for all three targets.
The watchdog driver introduced new HAL files for STM32 and stubs for
Zynq. The dynamic thread functions modified the scheduler, the IPC
subsystem, and the TCB layout. Any of these changes could break
architecture-specific code paths that only surface during
cross-compilation.
</p>

<p>
STM32F207: clean. STM32F407: clean. PYNQ-Z2: clean. Three targets,
three green builds, zero warnings. The dual build system and the
architecture abstraction layer did their job&mdash;the watchdog stubs
on Zynq compiled without error, the TCB layout changes were
architecture-neutral, and the scheduler modifications used no
platform-specific code.
</p>

<h3>Hardware Verification</h3>

<p>
Cross-compilation proves the code compiles. It does not prove the code
works. The F407 board was still connected from the previous evening's
debugging session, J-Link cable plugged in, serial terminal open. Flash.
Boot. Watch.
</p>

<p>
The IPC demo came up. The echo server registered. The echo client sent
its first message. The LED blinked. The shell prompt appeared. Type
<code>wdt</code>&mdash;watchdog enabled, feed count climbing. Type
<code>ps</code>&mdash;all threads present and accounted for. Type
<code>version</code>&mdash;0.10.0. The watchdog was running. The threads
were scheduling. The IPC was passing messages. The shell was responding.
Everything the night's work had touched was functioning on real silicon.
</p>

<h3>All Quiet on the Wire</h3>

<p>
The git log told the story. Three feature branches, each one merged to
main, each one pushed. The version string. The watchdog driver with its
eleven tests. The dynamic thread system with its thirteen tests. The
cross-compilation across all three targets. The hardware flash. All done.
All merged. All green.
</p>

<p>
321 tests passing. A watchdog guarding the idle thread. Dynamic thread
creation and destruction with full cleanup and slot reuse. A version
string that updates from a single source of truth. Three more pieces of
the RTOS locked into place, each one following the same discipline:
design, test, implement, verify on silicon, merge.
</p>

<div class="highlight">
<strong>Status after the Night Shift:</strong> ms-os v0.10.0 with
hardware watchdog (IWDG) feeding from the idle thread, dynamic thread
creation/destruction with TCB slot reuse, full IPC mailbox cleanup on
thread destroy, <code>wdt</code> shell command, and CMake-injected
version string. 321 C++ tests (up from 297). Cross-compiled for F207,
F407, and PYNQ-Z2. Verified on F407 hardware. All work completed
autonomously overnight.
</div>

<!-- ============================================================ -->
<!--         CHAPTER: PHASE 12 -- SPI / I2C / DMA DRIVERS          -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 12</span>
  The Bus Drivers
</h2>

<div class="epigraph">
  "The only way to test a peripheral driver is to talk to real silicon."
  <div class="attribution">&mdash; Embedded systems folklore</div>
</div>

<p>
Three new bus protocols. Three register maps. Three state machines.
Phase 12 brought DMA, SPI, and I2C into the HAL, each one a register-level
driver that talks directly to STM32 silicon without wrapping the vendor
library. The implementation order was deliberate: DMA first because future
DMA-backed SPI and I2C transfers would need it, SPI second because its
full-duplex protocol is simpler, and I2C last because its START/ADDR/STOP
state machine with ACK/NACK timing is the most complex of the three.
</p>

<h3>DMA: The Data Mover</h3>

<p>
The STM32 has two DMA controllers, each with 8 streams and 8 channel
selectors per stream. At the register level, each stream is a block of 6
registers at base + 0x10 + stream * 0x18: configuration, transfer count,
peripheral address, memory address, secondary memory address (for
double-buffering), and FIFO control. The status registers split streams
0-3 into LISR and 4-7 into HISR, with 5 flag bits per stream at irregular
offsets.
</p>

<p>
The DMA driver stores per-stream callback state in a static array:
<code>s_state[2][8]</code>&mdash;two controllers, eight streams each. When a
transfer completes, the ISR reads the status register, identifies which
flags are set (transfer complete or transfer error), clears them via the
flag clear register, and invokes the stored callback with the appropriate
flag bits. Sixteen ISR handlers in total, one per stream.
</p>

<h3>SPI: Full Duplex</h3>

<p>
SPI is conceptually simple: master generates a clock, data shifts out on
MOSI and in on MISO simultaneously. One byte out, one byte in. The polled
transfer loop is four lines: wait for TXE (transmit empty), write DR, wait
for RXNE (receive not empty), read DR. Repeat for each byte.
</p>

<p>
The async transfer uses the same byte-at-a-time approach but driven by
interrupts. Per-instance state tracks the tx/rx buffers, their lengths,
and current indices. The ISR checks RXNE first (read the received byte),
then TXE (write the next byte). When the last byte is received, the ISR
disables interrupts and invokes the completion callback.
</p>

<p>
The SPI loopback demo was the on-target verification vehicle. Wire PA7
(MOSI) to PA6 (MISO), and every byte the master sends comes right back.
Four tests: a single 0xA5 byte, a 4-byte pattern, a full 0x00-0xFF sweep,
and an async interrupt-driven transfer. Without the loopback wire, all
transfers complete (the driver does not hang) but the received data is
floating noise&mdash;FAIL is expected. With the wire, all four pass.
</p>

<h3>I2C: The State Machine</h3>

<p>
I2C is the most complex of the three. The STM32 I2C peripheral is
notoriously finicky&mdash;the write sequence requires START, wait for SB,
write address, wait for ADDR, clear ADDR by reading SR1 then SR2, then
for each byte wait for TXE, write DR, then wait for BTF before generating
STOP. The read sequence is even more involved: the number of bytes to
receive determines when to clear ACK and when to set STOP, with special
cases for 1-byte and 2-byte reads.
</p>

<p>
The ADDR flag clearing deserves mention. The STM32 I2C peripheral requires
reading SR1 followed by SR2 to clear the ADDR flag. The natural pattern is
<code>(void)reg(SR1); (void)reg(SR2);</code>&mdash;read and discard. But
ARM GCC 12 with <code>-Werror</code> warns that casting a volatile read to
void may allow the compiler to optimize away the access. The fix was a
<code>readDiscard()</code> helper that reads into a volatile local variable:
</p>

<pre>
<span class="kw">static void</span> <span class="fn">readDiscard</span>(std::uint32_t addr)
{
    <span class="kw">volatile</span> std::uint32_t tmp = *<span class="kw">reinterpret_cast</span>&lt;<span class="kw">volatile</span> std::uint32_t *&gt;(addr);
    (<span class="kw">void</span>)tmp;
}
</pre>

<p>
This guarantees the compiler generates the load instruction while silencing
the warning. The same pattern had been discovered in Phase 10 (watchdog SR
reads) and documented in the gotchas file.
</p>

<h3>RCC: Clock Gating</h3>

<p>
Each new peripheral needs its clock enabled before register access. Six new
functions in the RCC module: enable and disable for SPI (APB2ENR bit 12 for
SPI1, APB1ENR bits 14-15 for SPI2/3), I2C (APB1ENR bits 21-23), and DMA
(AHB1ENR bits 21-22). The Zynq stubs are no-ops, as always.
</p>

<h3>The snprintf Trap</h3>

<p>
The SPI demo originally used <code>std::snprintf</code> to format the test
summary. Cross-compilation blew up with an undefined <code>end</code>
symbol. The problem: snprintf in newlib (nano.specs) pulls in malloc, which
calls <code>_sbrk</code>, which references the linker symbol <code>end</code>
marking the end of the BSS segment. Our linker scripts do not define
<code>end</code>&mdash;the kernel manages its own heap via the Heap
allocator, not through the C library sbrk interface.
</p>

<p>
The fix was simple: do not use snprintf. The pass/total counts are
single-digit numbers; <code>'0' + pass</code> produces the ASCII digit
directly. No format strings, no printf machinery, no linker surprises.
</p>

<h3>53 New Tests</h3>

<p>
The mock-and-test pattern scaled cleanly. MockDma.cpp, MockSpi.cpp,
MockI2c.cpp, and MockRcc.cpp each record their function calls into global
vectors. The test files assert on those recorded calls. 8 RCC tests, 13
DMA tests, 14 SPI tests, 18 I2C tests. Every API function has at least one
test verifying its parameters are recorded correctly, and every injectable
return value (busy flag, remaining count, error code, receive data) has
a test verifying it propagates to the caller.
</p>

<p>
Host tests: 374 passing (up from 321). Cross-compilation: clean on all
three targets. Flash to F407: SPI demo runs, all transfers complete,
serial output confirmed. ipc-demo regression: still fully functional.
</p>

<div class="highlight">
<strong>Status after Phase 12:</strong> Three new HAL modules (DMA, SPI, I2C)
with register-level STM32 drivers, Zynq stubs, and 53 new host tests.
SPI loopback demo app verified on STM32F407. Total test count: 374 C++
tests, 135 Python tests. The bus drivers are ready for sensors, displays,
and external memory.
</div>


<!-- ============================================================ -->
<!--   CHAPTER 13: BOARD-TO-BOARD USART2 INTEGRATION TEST         -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Chapter 13</span>
  The Wire Between Two Worlds
</h2>

<div class="epigraph">
  "A peripheral driver is not truly tested until it talks to another device."
  <div class="attribution">&mdash; Embedded systems folklore</div>
</div>

<p>
Every phase up to this point had tested peripherals in isolation. SPI loopback
wired MOSI to MISO on the same chip. UART tests ran on the host with mocks.
The question lingered: does the UART driver actually work when two separate
boards talk to each other over real wires?
</p>

<p>
Phase 13 answered that question. Two identical STM32F407ZGT6 boards sat side
by side on the bench, their USART2 TX and RX pins cross-wired. Board 1 drove
its J-Link debug probe and printed test results on its USART1 console.
Board 2 drove its CMSIS-DAP debug probe and reported echo activity on its own
USART1 console. Between them, two wires carried the actual test traffic: PA2
(TX) on one board to PA3 (RX) on the other, and vice versa.
</p>

<h3>The Echo Server</h3>

<p>
Board 2 ran the simplest possible firmware: initialize USART2 with interrupt-
driven RX, then poll the ring buffer in a tight loop. Every byte that arrives
gets sent right back. The main loop also reports a running total on the
console, so the operator can see activity happening in real time. No kernel,
no threads, no scheduler&mdash;just a bare-metal echo loop that exercises
the exact same UART HAL code that the kernel uses.
</p>

<h3>The Test Runner</h3>

<p>
Board 1 ran a structured test harness with five tests of increasing
complexity:
</p>

<ol>
  <li><strong>Single byte</strong> &mdash; Send 0xA5, wait for echo, verify
      the returned byte matches. The simplest possible round-trip.</li>
  <li><strong>Multi-byte</strong> &mdash; Send {0xDE, 0xAD, 0xBE, 0xEF},
      verify all four bytes echo back in order. Tests that the ring buffer
      handles sequential bytes correctly.</li>
  <li><strong>Sequential</strong> &mdash; Send every byte value from 0x00
      through 0xFF, one at a time, verifying each echo. Tests that no byte
      value is special-cased or corrupted.</li>
  <li><strong>Burst</strong> &mdash; Send 16 bytes rapidly without waiting
      between sends, then collect all echoes. Tests the ring buffer under
      moderate burst load.</li>
  <li><strong>Stress</strong> &mdash; Send 64 bytes rapidly (the full ring
      buffer capacity), collect all echoes. The maximum burst the 64-byte
      ring buffer can handle without overflow.</li>
</ol>

<p>
Each test drains any stale bytes from the RX buffer before starting, sends
its pattern, and waits for echoed responses with a timeout loop. On
mismatch, the test prints the expected and actual byte values in hex for
immediate diagnosis. The final summary reports pass/total count.
</p>

<h3>Dual-Probe Flashing</h3>

<p>
With two boards, flashing became a two-step process. Board 1 used the
existing J-Link path. Board 2 needed its own path through the CMSIS-DAP
probe. A new <code>--probe cmsis-dap</code> argument in <code>build.py</code>
routes the flash command through OpenOCD with the CMSIS-DAP interface
configuration instead of J-Link. The same binary format, the same flash
address (0x08000000), just a different debug probe on the other end of the
USB cable.
</p>

<h3>What This Proves</h3>

<p>
No new HAL code was written for Phase 13. The UART driver, the RCC clock
enable, the GPIO alternate function configuration&mdash;all existed since
Phase 0. What Phase 13 proved is that the existing code works in the
scenario it was designed for: two devices communicating over UART at 115200
baud, with interrupt-driven receive and polled transmit, across physical
wires. The ring buffer handles bursts up to its full 64-byte capacity. The
baud rate calculation produces matching bit timing on two boards with
identical clock configurations. No bytes are lost, no bytes are corrupted,
no bytes arrive out of order.
</p>

<div class="highlight">
<strong>Status after Phase 13:</strong> First board-to-board peripheral test
passing. Two STM32F407 boards communicating over USART2 with 5 integration
tests (single byte, multi-byte, sequential 0x00-0xFF, 16-byte burst, 64-byte
stress). Dual-probe flashing via J-Link and CMSIS-DAP. Total test count: 389
C++ host tests, 135 Python tests.
</div>


<!-- ============================================================ -->
<!--                      EPILOGUE                                -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Epilogue</span>
  The Road Ahead
</h2>

<div class="epigraph">
  "The best way to predict the future is to implement it."
  <div class="attribution">&mdash; Alan Kay</div>
</div>

<p>
As of March 2026, ms-os has completed thirteen phases of development. It runs
on three hardware targets spanning two ARM architecture families, with
389 C++ unit tests and 135 Python tests verified by GitHub Actions CI on
every push. The kernel schedules 8 threads across 32 priority levels,
enforces a hardware privilege boundary with SVC syscalls and MPU protection,
communicates through Minix-style IPC, parses standard FDT device trees at
runtime, conserves power via WFI and sleep modes, drives SPI/I2C/DMA
peripherals at the register level, and provides an interactive shell for
runtime introspection. All of it cross-compiles for Cortex-M3, Cortex-M4,
and Cortex-A9 from the same source tree. And now, for the first time, two
boards talk to each other.
</p>

<p>
The journey from a blinking LED to a microkernel with IPC, device trees, and
CI has been one of accumulation. Each phase built on the infrastructure of
the last. The dual build system from Phase 0 made every subsequent phase
testable on the host. The architecture abstraction from Phase 4 made every
subsequent feature portable across three targets. The SVC dispatch from
Phase 6 made the IPC from Phase 5 available to unprivileged threads. Phase
13 proved that the HAL drivers work not just in isolation but across physical
wires between real devices. None of these phases exist in isolation; they
form a stack where each layer depends on the ones below.
</p>

<p>
But the journey is far from over. The roadmap includes:
</p>

<ul>
  <li><strong>User-space drivers</strong> &mdash; Move device drivers out
      of the kernel into user-space services communicating via IPC</li>
  <li><strong>SMP support</strong> &mdash; Utilize the PYNQ-Z2's second
      Cortex-A9 core with per-core scheduling and cross-core IPC</li>
  <li><strong>Filesystem</strong> &mdash; A minimal filesystem for
      configuration storage and logging</li>
  <li><strong>Custom bootloader</strong> &mdash; Replace u-boot with our own,
      using <code>ps7_init</code> for standalone Zynq PS initialization</li>
  <li><strong>Networking</strong> &mdash; A lightweight TCP/IP stack for
      the STM32 Ethernet peripheral</li>
  <li><strong>Board-to-board SPI and I2C</strong> &mdash; Extend the
      cross-board test infrastructure to SPI master/slave and I2C</li>
</ul>

<p>
Each phase builds on the last. Each line of assembly teaches something that
no textbook can. Every bug is a lesson&mdash;and every fix is a celebration.
Somewhere in the intersection of silicon and software, an operating system
continues to grow.
</p>

<!-- ============================================================ -->
<!--                    APPENDIX A                                -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Appendix A</span>
  Hardware Targets
</h2>

<table>
<tr>
  <th>Board</th>
  <th>SoC</th>
  <th>Core</th>
  <th>Clock</th>
  <th>Flash</th>
  <th>RAM</th>
</tr>
<tr>
  <td>Custom (F207)</td>
  <td>STM32F207ZGT6</td>
  <td>Cortex-M3</td>
  <td>120 MHz</td>
  <td>1 MB</td>
  <td>128 KB SRAM</td>
</tr>
<tr>
  <td>Custom (F407)</td>
  <td>STM32F407ZGT6</td>
  <td>Cortex-M4</td>
  <td>168 MHz</td>
  <td>1 MB</td>
  <td>128 KB + 64 KB CCM</td>
</tr>
<tr>
  <td>PYNQ-Z2</td>
  <td>Zynq-7020</td>
  <td>Dual Cortex-A9</td>
  <td>650 MHz</td>
  <td>(SD card)</td>
  <td>512 MB DDR3</td>
</tr>
</table>

<h3>Build Sizes (Threads App)</h3>

<table>
<tr><th>Target</th><th>.text</th><th>.data</th><th>.bss</th><th>Total</th></tr>
<tr><td>STM32F207</td><td>8,240 B</td><td>12 B</td><td>35,840 B</td><td>44,092 B</td></tr>
<tr><td>STM32F407</td><td>8,360 B</td><td>12 B</td><td>35,840 B</td><td>44,212 B</td></tr>
<tr><td>PYNQ-Z2</td><td>10,740 B</td><td>8 B</td><td>54,272 B</td><td>65,020 B</td></tr>
</table>

<!-- ============================================================ -->
<!--                    APPENDIX B                                -->
<!-- ============================================================ -->
<h2 class="chapter">
  <span class="ch-num">Appendix B</span>
  Project Timeline
</h2>

<div class="timeline">
  <div class="event">
    <div class="event-title">Phase 0 &mdash; Foundation</div>
    Toolchain, HAL (GPIO, UART, RCC), startup assembly, dual build system,
    link-time mock testing. First LED blink and serial output on F207.
  </div>
  <div class="event">
    <div class="event-title">Phase 1 &mdash; Kernel Core</div>
    Thread creation, PendSV context switch, SVC first-thread launch,
    SysTick tick handler, three-layer crash dump system. Hardware verified
    on F207 and F407.
  </div>
  <div class="event">
    <div class="event-title">Phase 2 &mdash; Scheduling</div>
    32-priority bitmap scheduler, round-robin time slicing, mutex with
    mandatory priority inheritance, counting semaphore, sleep/yield,
    wait queues. 136 host tests passing.
  </div>
  <div class="event">
    <div class="event-title">Phase 3 &mdash; Memory Management</div>
    Block pool (O(1) fixed-size), heap (first-fit + coalescing), MPU
    configuration (6 regions, per-thread stack protection), C++ operator
    new/delete overloads.
  </div>
  <div class="event">
    <div class="event-title">Phase 4A &mdash; PYNQ-Z2 Bringup</div>
    ARM mode startup, DDR linker script, Zynq UART/RCC/GPIO HAL,
    OpenOCD JTAG configuration. Cross-compilation for Cortex-A9.
  </div>
  <div class="event">
    <div class="event-title">Phase 4B &mdash; Cortex-A9 RTOS Port</div>
    Arch.h abstraction, GIC/private timer drivers, IRQ-based context
    switch with SRS/RFE, fault handlers, crash dump for A9.
  </div>
  <div class="event">
    <div class="event-title">Phase 4 Hardware Bringup &mdash; The Debugging Saga</div>
    Alignment fault (DFSR=0x801) diagnosed as MMU-disabled Strongly Ordered
    memory. Built flat 1:1 MMU with 16 KB L1 translation table. Fixed UART
    ID mapping (Usart1 to Uart0). Discovered L2 cache stale code problem
    on JTAG reload; solved with OpenOCD TCL cache invalidation script.
    Full RTOS verified running on PYNQ-Z2 via both JTAG and SD card boot.
  </div>
  <div class="event">
    <div class="event-title">Phase 4 &mdash; The Register Ghost</div>
    Identified and fixed r4/r5 callee-saved register clobbering in the
    Cortex-A9 IRQ handler. The GIC base address (0xF8F00100) was being
    written to r4 before the context switch saved it, destroying interrupted
    threads' local variables. Added thread-safe UART at the HAL level
    with interrupt save/restore guards. All three threads verified correct
    on PYNQ-Z2 hardware.
  </div>
  <div class="event">
    <div class="event-title">Phase 5 &mdash; IPC Message Passing</div>
    Minix-style synchronous send/receive/reply with 64-byte fixed messages,
    per-thread 4-slot mailboxes, async notifications (32-bit bitmask),
    Python IDL code generator (ipcgen), and Echo service demo app.
  </div>
  <div class="event">
    <div class="event-title">Phase 6 &mdash; Syscall Interface</div>
    Unprivileged threads via ARM CONTROL register nPRIV bit. SVC dispatch
    with 23 syscall numbers covering the full kernel API. Handler-mode
    g_inSyscall flag to allow blocking inside SVC context.
  </div>
  <div class="event">
    <div class="event-title">Phase 7 &mdash; Device Tree</div>
    Replaced custom YAML dtgen with standard FDT binary device tree.
    DTS v1 source files for all three boards, Python fdtlib DTB builder,
    dtb2cpp embedder, read-only kernel FDT parser. Shell dt command for
    runtime board config display.
  </div>
  <div class="event">
    <div class="event-title">Phase 8 &mdash; Power Management</div>
    WFI in idle thread, sleep-on-exit (SLEEPONEXIT bit), deep sleep
    (SLEEPDEEP bit). Three-function arch API. Mock state tracking for
    host testing.
  </div>
  <div class="event">
    <div class="event-title">Phase 9 &mdash; Interactive Shell</div>
    Character-driven CLI over UART with six commands: help, ps, mem,
    uptime, version, dt. Function-pointer I/O for host testability.
    Custom integer and hex formatters for freestanding environment.
  </div>
  <div class="event">
    <div class="event-title">Phase 10 &mdash; Hardware Watchdog</div>
    Independent Watchdog (IWDG) register-level driver for STM32F2/F4.
    Integrated with kernel idle thread: if any high-priority thread
    starves the idle loop, the watchdog counter expires and resets the MCU.
    Shell &ldquo;wdt&rdquo; command for status reporting. 8 new HAL tests.
  </div>
  <div class="event">
    <div class="event-title">Phase 11 &mdash; Dynamic Threads</div>
    TCB slot reuse via Inactive-state scanning. destroyThread() performs
    coordinated cleanup: scheduler removal, IPC mailbox reset, TCB zeroing.
    Thread IDs recycled after destruction. Idle thread protected from
    destruction. 13 new kernel tests.
  </div>
  <div class="event">
    <div class="event-title">Phase 12 &mdash; SPI / I2C / DMA Drivers</div>
    Three new register-level HAL modules: DMA (dual controller, 8 streams
    each, interrupt callbacks), SPI (full-duplex master with polled and
    async transfers), and I2C (standard/fast mode with read/write/writeRead
    and async variants). Extended RCC with clock gating for all three
    peripherals. Zynq no-op stubs for all modules. SPI loopback demo app
    verified on STM32F407 (4 tests: polled single-byte, polled multi-byte,
    0x00-0xFF pattern sweep, async interrupt-driven transfer). 53 new host
    tests across 4 test files. Debug findings: serial output timing for
    one-shot apps, ARM GCC volatile read-discard warning, snprintf linking
    issue in freestanding environments.
  </div>
  <div class="event">
    <div class="event-title">CI &amp; GitHub Pages</div>
    GitHub Actions CI with 8 parallel jobs: 4 host-test matrix cells
    (GCC/Clang x Debug/Release), Python tests, and 3 cross-compilation
    targets. GitHub Pages deployment for project documentation.
    374 C++ tests, 135 Python tests.
  </div>
</div>

<div style="text-align: center; margin-top: 4cm; color: #999; font-style: italic;">
  &mdash; End &mdash;
</div>

</body>
</html>
